{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n06UwLqYD-y4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  1 What is a parameter?\n",
        "  \n",
        "  -> A parameter is a value or variable that helps define or control the behavior of a system, model, or function. Its meaning depends a little on the context, but here are the main ways itâ€™s used:\n",
        "\n",
        "  ** in statisstis**\n",
        "    * A parameter is a numerical characteristic of a population (like the mean, variance, or proportion).\n",
        "\n",
        "    * Example: If we want to know the average height of all adults in India, that true average is a parameter. We usually estimate it using a sample.\n",
        "\n",
        "     **in machine learning**\n",
        "    * Parameters are the internal values that a model learns during training to make predictions.\n",
        "    * Example: In linear regression, the slope and intercept (y = mx+c) are parameters.\n",
        "     * Neural networks have millions of parameters (weights and biases) that adjust during training.\n",
        "\n",
        "**in programming**\n",
        "   A parameter is a variable passed into a function to customize its behavior.\n"
      ],
      "metadata": {
        "id": "vWTedTgBWS4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(name):\n",
        "  return{\"hello,{name}!\"}"
      ],
      "metadata": {
        "id": "h4vC8PaEYUth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  2 What is correlation?\n",
        "  \n",
        "   ->   Correlation is a statistical measure that describes the strength and direction of a relationship between two variables.\n",
        "    *  It tells us whether, and how strongly, pairs of variables are related.\n",
        "     * The correlation value is usually expressed as the correlation coefficient (r), which ranges between -1 and +1.\n",
        "\n",
        "     **types  of correlation**\n",
        "      * Positive Correlation (r > 0): When one variable increases, the other also increases.          \n",
        "       Example: Height and weight â€” taller people often weigh more.\n",
        "      * Negative Correlation (r < 0):                    When one variable increases, the other decreases. Example: Speed of a car and travel time â€” higher speed reduces travel time.\n",
        "      * Zero Correlation (r â‰ˆ 0):                         No relationship between the variables.        Example: Shoe size and IQ.\n",
        "\n",
        "       ðŸ“ˆ Interpreting the Correlation Coefficient\n",
        "       value of r              \tMeaning\n",
        "          +1\t                 Perfect positive correlation\n",
        "          -1            \t     Perfect negative correlation\n",
        "           0\t                  No correlation\n",
        "  Between 0.7 and 1 or -0.7 and -1     \tStrong correlation\n",
        " Between 0.3 and 0.7 or -0.3 and -0.7\t  Moderate correlation\n",
        " Between 0 and 0.3 or -0.3 and 0\t      Weak correlation\n",
        "    Important Note\n",
        "   Correlation does not imply causation.\n",
        "\n",
        "  Just because two variables move together doesnâ€™t mean one causes the other.\n",
        "\n",
        "  Example: Ice cream sales and drowning incidents are positively correlated (both rise in summer), but ice cream doesnâ€™t cause drowning.\n"
      ],
      "metadata": {
        "id": "tmeg8U3Keb_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  3  Define Machine Learning. What are the main components in Machine Learning?\n",
        "  \n",
        "  -> Machine Learning (ML) is a branch of Artificial Intelligence (AI) that focuses on building systems that can learn patterns from data and improve their performance over time without being explicitly programmed.\n",
        "\n",
        "  Instead of writing fixed rules, we provide data and algorithms that allow the system to discover relationships and make predictions or decisions.\n",
        "\n",
        "   Example: A spam filter learns to classify emails as spam or not spam by analyzing examples rather than relying on hard-coded rules.\n",
        "\n",
        "# main components of machine learning\n",
        "    *   Date\n",
        "\n",
        "   . The foundation of ML. It can be structured (tables, databases) or unstructured (images, text, audio).\n",
        "\n",
        "   . Example: Customer purchase history, medical records, sensor readings.\n",
        "\n",
        "    * Features\n",
        "\n",
        "  . The measurable properties or variables extracted from raw data.\n",
        "\n",
        "  .Example: For house price prediction, features could be square footage, number of rooms, and location.\n",
        "\n",
        "    * Model\n",
        "\n",
        "  .The mathematical or computational structure that maps input features to output predictions.\n",
        "\n",
        "   .Examples: Linear regression, decision trees, neural networks.\n",
        "\n",
        "    * Training\n",
        "\n",
        "  .The process of feeding data into the model so it can learn patterns.\n",
        "\n",
        "  .Involves adjusting parameters (like weights in neural networks) to minimize errors.\n",
        "\n",
        "    *  Testing/Validation\n",
        "\n",
        "  .Evaluating the model on unseen data to check how well it generalizes.\n",
        "\n",
        "  .Helps avoid overfitting (when a model memorizes training data but fails on new data).  \n",
        "\n",
        "    *  Loss Function\n",
        "\n",
        "  . A mathematical function that measures how far the modelâ€™s predictions are from the actual values.\n",
        "\n",
        "  .Example: Mean Squared Error (MSE) for regression tasks.\n",
        "\n",
        "    *  Optimizer\n",
        "\n",
        "  .An algorithm that updates model parameters to minimize the loss function.\n",
        "\n",
        "   .Examples: Gradient Descent, Adam.\n",
        "\n",
        "    * Prediction/Inference\n",
        "\n",
        "   Once trained, the model can make predictions on new, unseen data.\n",
        "\n",
        "   Example: Predicting tomorrowâ€™s stock price based on historical data."
      ],
      "metadata": {
        "id": "TPsR9dRtkg9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  4 How does loss value help in determining whether the model is good or not?\n",
        "  \n",
        "  ->The loss value (also called the cost or error) is a numerical measure of how far a modelâ€™s predictions are from the actual target values. Itâ€™s central to determining whether a model is â€œgoodâ€ or not.\n",
        "\n",
        "     * ndicator of Performance\n",
        "\n",
        "  A low loss value means the modelâ€™s predictions are close to the true values.\n",
        "\n",
        "  A high loss value means the model is making large errors.\n",
        "\n",
        "     * Training Feedback\n",
        "\n",
        "   During training, the model adjusts its parameters to minimize the loss.\n",
        "\n",
        "   The optimizer uses the loss value as feedback to decide how to update weights.\n",
        "\n",
        "     * Model Comparison\n",
        "\n",
        "  Loss values allow us to compare different models or algorithms.\n",
        "\n",
        "  Example: If Model A has a loss of 0.05 and Model B has 0.20 on the same dataset, Model A is performing better.\n",
        "\n",
        "     *  Generalization Check\n",
        "\n",
        "  Loss is measured on both training data and validation/test data.\n",
        "\n",
        "  If training loss is low but validation loss is high, the model is overfitting (memorizing training data but failing on new data).\n",
        "\n",
        " A good model has consistently low loss across both sets.\n",
        "\n",
        "    *  Choice of Loss Function\n",
        "\n",
        "  The definition of â€œgoodâ€ depends on the chosen loss function:\n",
        "\n",
        "  Regression tasks: Mean Squared Error (MSE), Mean Absolute Error (MAE).\n",
        "\n",
        "  Classification tasks: Cross-Entropy Loss, Hinge Loss.\n",
        "\n",
        " Each loss function emphasizes different aspects of error.\n",
        "\n",
        "    Example\n",
        "  Imagine predicting house prices:\n",
        "\n",
        "  True price = â‚¹50 lakh\n",
        "\n",
        "  Model prediction = â‚¹48 lakh\n",
        "  Error = â‚¹2 lakh\n",
        "\n",
        "  If the loss function is Mean Squared Error (MSE):\n",
        "\n",
        "              Loss = (50-48)2 = 4\n",
        "  This small loss indicates the model is fairly accurate.\n"
      ],
      "metadata": {
        "id": "4cwgmNlKsm-H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qw69YziLxTXh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  5 What are continuous and categorical variables?\n",
        "  \n",
        "   ->In data science and machine learning, variables are the building blocks of datasets. They represent the characteristics or features we analyze. Broadly, they fall into two types:\n",
        "\n",
        "    Continuous Variables\n",
        "   Definition: Variables that can take an infinite number of values within a given range.\n",
        "   Nature: Numeric, measurable, and often fractional.\n",
        "  Examples:\n",
        "\n",
        "      Height (e.g., 170.5 cm)\n",
        "      Weight (e.g., 65.2 kg)\n",
        "      Temperature (e.g., 36.7 Â°C)\n",
        "      Time (e.g., 2.35 seconds)\n",
        "  Key Point: You can perform arithmetic operations (addition, averaging, etc.) on them.\n",
        "\n",
        "    Categorical Variables\n",
        "   Definition: Variables that represent distinct groups or categories.\n",
        "  Nature: Qualitative, descriptive, and not inherently numeric.\n",
        "  Examples:\n",
        "     Gender (Male, Female, Other)\n",
        "     Colors (Red, Blue, Green)\n",
        "     City names (Delhi, Mumbai, Patna)\n",
        "     Yes/No responses\n",
        "   Key Point: They classify data into groups. Arithmetic operations donâ€™t make sense here (e.g., â€œBlue + Redâ€ is meaningless).\n",
        "\n",
        "    omparison Table\n",
        "Aspect\t  Continuous Variables     \tCategorical Variables\n",
        "  Type\t    Quantitative           \tQualitative\n",
        "Values\t  Infinite, measurable\t   Finite, distinct\n",
        "Examples\t  Height, weight, age   \tGender, color, city\n",
        "Operations  \tArithmetic possible\t  Only grouping/counting\n",
        "Representation\t Numbers\t            Labels/strings\n"
      ],
      "metadata": {
        "id": "wP3JX-mp_QwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  6 how do we handle categorical variables in machine learning? what are the common t echniques?\n",
        "  \n",
        "    ->Categorical variables represent discrete groups or categories (e.g., gender, color, city). Since ML models canâ€™t directly process text labels, we need to encode them into numbers.\n",
        "\n",
        "      Common Techniques to Handle Categorical Variables\n",
        "     1 Label Encoding\n",
        "       Assigns each category a unique integer.\n",
        "        Example:\n"
      ],
      "metadata": {
        "id": "T7oAbstmCUgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "color = {\"Red\": 0, \"Blue\": 1, \"Green\": 2}"
      ],
      "metadata": {
        "id": "QJ9FvUMXFEjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    * One-Hot Encoding\n",
        "   Creates a new binary column for each category.\n",
        "   Example:"
      ],
      "metadata": {
        "id": "FaXG7FQ0GO3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "color:{\n",
        "\"Red\":[1, 0, 0],\n",
        "\"Blue\": [0, 1, 0],\n",
        "\"Green\": [0, 0, 1],\n",
        "}"
      ],
      "metadata": {
        "id": "pftTP0Y0GplR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    3 Ordinal Encoding\n",
        "      Used when categories have a natural order.\n",
        "      Example: Education level:"
      ],
      "metadata": {
        "id": "2i4UCvSWHYkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ordinal_mapping = {\n",
        "    \"High School\": 1,\n",
        "    \"Bachelor\": 2,\n",
        "    \"Master\": 3,\n",
        "    \"PhD\": 4\n",
        "}"
      ],
      "metadata": {
        "id": "hlHMJrRIHm2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 7 What do you mean by training and testing a dataset?\n",
        "\n",
        "    -> Training a Dataset\n",
        "    Definition: Training is the process of teaching the model using historical data.\n",
        "    Purpose: The model learns patterns, relationships, and adjusts its parameters (weights, biases).\n",
        "\n",
        "   Process:\n",
        "     Input features (X) and target labels (y) are fed into the algorithm.\n",
        "     The model makes predictions.\n",
        "     The loss function calculates errors.\n",
        "     The optimizer updates parameters to reduce errors.\n",
        "     Example: In predicting house prices, the training dataset includes features like square footage, location, and the actual house prices. The model learns the relationship between features and price.\n",
        "\n",
        "    Testing a Dataset\n",
        "   Definition: Testing evaluates the trained model on unseen data (data not used during training).\n",
        "   Purpose: To check if the model generalizes well beyond the training set.\n",
        "   Process:\n",
        "   The trained model makes predictions on the test dataset.\n",
        "   Performance metrics (accuracy, precision, recall, RMSE, etc.) are calculated.\n",
        "   Example: After training the house price model, we test it on new houses the model hasnâ€™t seen before to see if predictions are close to actual prices.\n",
        "\n",
        "\n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "me12Jlp8IztX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 8 What is sklearn.preprocessing?\n",
        "\n",
        "    -> In scikit-learn (a popular Python machine learning library), sklearn.preprocessing is a module that provides tools for preprocessing data before feeding it into machine learning models. Preprocessing is essential because raw data often contains inconsistencies, different scales, or categorical values that models cannot directly handle.\n",
        "\n",
        "    What It Does\n",
        "  * The preprocessing module helps with:\n",
        "     Scaling and Normalization\n",
        "   Ensures features are on similar scales so that models donâ€™t get biased by large-valued features.\n",
        "   Examples:\n",
        "      StandardScaler â†’ scales data to have mean = 0 and variance = 1.\n",
        "      MinMaxScaler â†’ scales values to a fixed range (usually 0 to 1).\n",
        "      Normalizer â†’ scales rows to unit norm.\n",
        "\n",
        "    *Encoding Categorical Variables\n",
        "      Converts non-numeric categories into numeric form.\n",
        "       Examples:\n",
        "        LabelEncoder â†’ assigns integer values to categories.\n",
        "        OneHotEncoder â†’ creates binary columns for each category.\n",
        "    *Polynomial and Interaction Features\n",
        "     Generates new features by combining existing ones.\n",
        "     Example: PolynomialFeatures can create squared or interaction terms (like x1.x2)\n",
        "\n",
        "    *Binarization\n",
        "     Converts numerical values into binary (0/1) based on a threshold.\n",
        "     Example: Binarizer can turn values greater than 5 into 1, else 0.\n",
        "\n",
        "    *Imputation\n",
        "     Handles missing values.\n",
        "     Example: SimpleImputer can replace missing values with mean, median, or mod\n",
        "\n"
      ],
      "metadata": {
        "id": "SpFHVIUYOxCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Example dataset\n",
        "X = np.array([[1, \"Red\"], [2, \"Blue\"], [3, \"Green\"]])\n",
        "\n",
        "# Scaling numerical feature\n",
        "scaler = StandardScaler()\n",
        "scaled_values = scaler.fit_transform([[1], [2], [3]])\n",
        "print(\"Scaled:\", scaled_values)\n",
        "\n",
        "# Encoding categorical feature\n",
        "encoder = OneHotEncoder()\n",
        "encoded_values = encoder.fit_transform([[\"Red\"], [\"Blue\"], [\"Green\"]]).toarray()\n",
        "print(\"Encoded:\", encoded_values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQkR0lzpQx5y",
        "outputId": "d3901c24-d0e1-41a6-9d02-3e06cfbc1d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled: [[-1.22474487]\n",
            " [ 0.        ]\n",
            " [ 1.22474487]]\n",
            "Encoded: [[0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  8  What is sklearn.preprocessing?\n",
        "  \n",
        "    -> sklearn.preprocessing is a module in scikit-learn that provides tools to transform raw data into a format suitable for machine learning models. It includes functions and classes for scaling, normalizing, encoding, and imputing data so that algorithms can learn effectively.\n",
        "\n",
        "    *Scaling and Normalization\n",
        "     StandardScaler â†’ removes mean and scales to unit variance.\n",
        "     MinMaxScaler â†’ scales values to a fixed range (usually 0â€“1).\n",
        "     RobustScaler â†’ reduces the influence of outliers.\n",
        "     Normalizer â†’ scales rows to unit norm (useful for text or sparse data).\n",
        "\n",
        "    *Encoding Categorical Variables\n",
        "     LabelEncoder â†’ converts categories into integers.\n",
        "     OneHotEncoder â†’ creates binary columns for each category.\n",
        "     OrdinalEncoder â†’ encodes ordered categories with integers.\n",
        "\n",
        "    *Feature Engineering\n",
        "     PolynomialFeatures â†’ generates polynomial and interaction terms.\n",
        "     Binarizer â†’ converts values into binary (0/1) based on a threshold.\n",
        "\n",
        "    *Handling Missing Data\n",
        "    Imputation tools (like SimpleImputer) replace missing values with mean, median, or most frequent values.\n",
        "\n"
      ],
      "metadata": {
        "id": "dsyo_RxjRHrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Example dataset\n",
        "X = np.array([[1, \"Red\"], [2, \"Blue\"], [3, \"Green\"]])\n",
        "\n",
        "# Scaling numerical feature\n",
        "scaler = StandardScaler()\n",
        "scaled_values = scaler.fit_transform([[1], [2], [3]])\n",
        "print(\"Scaled:\", scaled_values)\n",
        "\n",
        "# Encoding categorical feature\n",
        "encoder = OneHotEncoder()\n",
        "encoded_values = encoder.fit_transform([[\"Red\"], [\"Blue\"], [\"Green\"]]).toarray()\n",
        "print(\"Encoded:\", encoded_values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8gsqwJVS2ME",
        "outputId": "45a13821-b49b-4451-8d96-db4cdf59364d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled: [[-1.22474487]\n",
            " [ 0.        ]\n",
            " [ 1.22474487]]\n",
            "Encoded: [[0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 9 What is a Test set?\n",
        "\n",
        "    ->A test set is a portion of your dataset that is set aside to evaluate the performance of a trained machine learning model. It contains data that the model has never seen during training, which makes it the best way to check how well the model generalizes to new, unseen data.\n",
        "\n",
        "    *Key Characteristics of a Test Set\n",
        "     Unseen Data: The test set is not used during training, so it provides an unbiased evaluation.\n",
        "     Purpose: Measures how well the model performs in real-world scenarios.\n",
        "     Evaluation Metrics: Accuracy, precision, recall, F1-score, RMSE, etc. are calculated using predictions on the test set.\n",
        "     Size: Typically 20â€“30% of the dataset (while 70â€“80% is used for training).\n",
        "     \n",
        "    *Why Itâ€™s Important\n",
        "     Prevents overfitting: A model might perform very well on training data but fail on new data.\n",
        "     Provides a realistic estimate of how the model will behave in production.\n",
        "     Helps compare different models fairly (using the same test set).\n",
        "\n",
        "    *Example\n",
        "     Suppose you have 1,000 rows of data for predicting student exam scores:\n",
        "     Training set: 800 rows â†’ used to teach the model.\n",
        "     Test set: 200 rows â†’ used to check if the model predicts exam scores correctly for students it hasnâ€™t seen before.\n"
      ],
      "metadata": {
        "id": "QEogIW_fTAxs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 10 How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        " How do you approach a Machine Learning problem?\n",
        "    ->In machine learning, we split data into training and testing sets to evaluate how well a model generalizes.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oX2v2ng6Uffl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Example dataset\n",
        "X = np.array([[1], [2], [3], [4], [5], [6]])   # Features\n",
        "y = np.array([1, 2, 3, 4, 5, 6])               # Labels\n",
        "\n",
        "# Split data: 80% training, 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training set:\", X_train, y_train)\n",
        "print(\"Testing set:\", X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrfn53_dVnIf",
        "outputId": "21c63b7a-7801-42ae-9d39-c5656949e5fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: [[6]\n",
            " [3]\n",
            " [5]\n",
            " [4]] [6 3 5 4]\n",
            "Testing set: [[1]\n",
            " [2]] [1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    *How to Approach a Machine Learning Problem\n",
        "     A structured approach helps ensure you donâ€™t miss critical steps. Hereâ€™s a common workflow:\n",
        "\n",
        "   * Define the Problem\n",
        "     Understand the business or research question.\n",
        "     Example: Predict house prices, classify emails as spam/not spam.\n",
        "\n",
        "   * Collect Data\n",
        "     Gather relevant datasets (structured, unstructured, or both).\n",
        "     Ensure data quality and sufficient size.\n",
        "\n",
        "   *Explore Data (EDA)\n",
        "     Perform Exploratory Data Analysis (EDA): visualize distributions, check correlations, detect missing values/outliers.\n",
        "     Helps you understand patterns and potential preprocessing needs.\n",
        "\n",
        "   * Preprocess Data\n",
        "     Handle missing values (imputation).\n",
        "     Encode categorical variables (Label/One-Hot Encoding).\n",
        "     Scale numerical features (StandardScaler, MinMaxScaler).\n",
        "\n",
        "   * Split Data\n",
        "     Divide into training and testing sets (and sometimes validation).\n",
        "\n",
        "   * Choose a Model\n",
        "     Select algorithms suitable for the task (Regression, Classification, Clustering, etc.).\n",
        "     Example: Linear Regression for continuous prediction, Decision Trees for classification.\n",
        "\n",
        "  * Train the Model\n",
        "     Fit the model on the training data.\n",
        "     Adjust parameters (weights, biases) using optimizers.\n",
        "\n",
        "   * Evaluate the Model\n",
        "     Use the test set to measure performance.\n",
        "     Metrics: Accuracy, Precision, Recall, F1-score, RMSE, etc.\n",
        "\n",
        "   * Tune Hyperparameters\n",
        "     Use techniques like Grid Search or Random Search.\n",
        "     Sometimes employ cross-validation for robust evaluation.\n",
        "\n",
        "  * Deploy & Monitor\n",
        "     Deploy the model into production.\n",
        "     Continuously monitor performance and retrain with new data if needed.\n"
      ],
      "metadata": {
        "id": "xp7SChRvV3_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 11 Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "    ->Exploratory Data Analysis (EDA) is the process of examining and visualizing data before applying machine learning models. Itâ€™s a critical step because it helps you understand the datasetâ€™s structure, quality, and relationships. Skipping EDA often leads to poor models and misleading results.\n",
        "\n",
        "\n",
        "    Reasons to Perform EDA\n",
        "   * Understand Data Distribution\n",
        "  Check how features are spread (normal, skewed, uniform).\n",
        "  Example: Income data is often skewed; knowing this helps decide whether to log-transform it.\n",
        "\n",
        "   * Detect Missing Values\n",
        "   Identify gaps in the dataset.\n",
        "   Example: If 30% of â€œAgeâ€ values are missing, you must impute or drop them before training.\n",
        "\n",
        "  * Spot Outliers\n",
        "   Outliers can distort models (especially regression).\n",
        "   Example: A house priced at â‚¹100 crore in a dataset of â‚¹50â€“80 lakh homes will mislead predictions.\n",
        "\n",
        "   * Identify Feature Relationships\n",
        "   Use correlation analysis to see how variables relate.\n",
        "   Example: Strong correlation between â€œStudy Hoursâ€ and â€œExam Scoreâ€ suggests predictive power.\n",
        "\n",
        "   * Handle Categorical Variables\n",
        "     Discover categorical features and decide encoding methods (Label Encoding, One-Hot Encoding).\n",
        "\n",
        "   * Feature Selection\n",
        "     EDA helps identify irrelevant or redundant features.\n",
        "     Example: If â€œEmployee IDâ€ has no predictive value, it should be dropped.\n",
        "\n",
        "    * Prevent Data Leakage\n",
        "     Ensures target-related information isnâ€™t accidentally included in features.\n",
        "\n",
        "    * Guide Model Choice\n",
        "     EDA reveals whether the problem is regression, classification, or clustering.\n",
        "     Example: If the target variable is continuous â†’ regression; if categorical â†’ classification.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xQ-tlcvkX0EA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12  What is correlation?\n",
        "\n",
        "    ->Correlation is a statistical concept that measures the strength and direction of the relationship between two variables. It tells us whether changes in one variable are associated with changes in another.\n",
        "\n",
        "\n",
        "   * Correlation Coefficient (r):\n",
        "     Ranges between -1 and +1                       Positive values â†’ variables move in the same direction.\n",
        "     Negative values â†’ variables move in opposite directions.\n",
        "     Zero â†’ no relationship.\n",
        "\n",
        "    * Types of Correlation\n",
        "      Positive Correlation (r > 0):                     When one variable increases, the other also increases.                                     Example: Height and weight â€” taller people often weigh more.\n",
        "\n",
        "     . Negative Correlation (r < 0): When one variable increases, the other decreases. Example: Speed of a car and travel time â€” higher speed reduces travel time.\n",
        "\n",
        "     No Correlation (r â‰ˆ 0): No meaningful relationship. Example: Shoe size and exam scores.\n",
        "\n",
        "    * Correlation â‰  Causation                           Just because two variables are correlated doesnâ€™t mean one causes the other.                           Example: Ice cream sales and drowning incidents are positively correlated (both rise in summer), but ice cream doesnâ€™t cause drowning.\n",
        "\n"
      ],
      "metadata": {
        "id": "TPtCFeJOZ7oO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example dataset\n",
        "data = {'Hours_Studied': [2, 4, 6, 8, 10],\n",
        "        'Exam_Score': [50, 60, 70, 80, 90]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate correlation\n",
        "print(df.corr())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-X-hjjIbt7p",
        "outputId": "b47980b1-65c0-4cc1-881a-969ddf98eb46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Hours_Studied  Exam_Score\n",
            "Hours_Studied            1.0         1.0\n",
            "Exam_Score               1.0         1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "13  What does negative correlation mean?\n",
        "\n",
        "\n",
        "    ->Negative correlation means that when one variable increases, the other variable decreases â€” they move in opposite directions.\n",
        "     \n",
        "  The correlation coefficient (r) is less than 0 (ranges between -1 and 0).\n",
        "  r = -1 â†’ perfect negative correlation (variables move exactly opposite).\n",
        "  r â‰ˆ 0 â†’ no correlation.\n",
        "\n",
        "  * Examples\n",
        "  Speed of a car vs. travel time: As speed increases, travel time decreases.\n",
        "  Price of a product vs. demand: As price goes up, demand usually goes down.\n",
        "  Exercise vs. body fat percentage: More exercise often leads to lower body fat.\n"
      ],
      "metadata": {
        "id": "cJsAcB2DbyeN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14  How can you find correlation between variables in Python?\n",
        "\n",
        "    ->reat question! In Python, you can find correlation between variables using libraries like pandas, numpy, or visualization tools like seaborn. Letâ€™s break it down\n",
        "\n",
        "   * using  pandas as pd\n",
        "\n"
      ],
      "metadata": {
        "id": "b_l4Qsk_ea-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example dataset\n",
        "data = {\n",
        "    'Hours_Studied': [2, 4, 6, 8, 10],\n",
        "    'Exam_Score': [50, 60, 70, 80, 90],\n",
        "    'Sleep_Hours': [8, 7, 6, 5, 4]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Correlation matrix\n",
        "print(df.corr())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqd1UBy5fEFV",
        "outputId": "d2012b84-7185-4709-a6b0-60b80acdbd19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Hours_Studied  Exam_Score  Sleep_Hours\n",
            "Hours_Studied            1.0         1.0         -1.0\n",
            "Exam_Score               1.0         1.0         -1.0\n",
            "Sleep_Hours             -1.0        -1.0          1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "KOSAsdW1fYcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x = [2, 4, 6, 8, 10]   # Hours studied\n",
        "y = [50, 60, 70, 80, 90]  # Exam score\n",
        "\n",
        "corr_matrix = np.corrcoef(x, y)\n",
        "print(corr_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcXHWMz8fdoH",
        "outputId": "315e96cd-52ec-4718-9d5f-4cba623cac7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1.]\n",
            " [1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Visualizing with Seaborn Heatmap"
      ],
      "metadata": {
        "id": "clpiT3p1flJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "Azh7VGVafm1s",
        "outputId": "a8f89f37-c26e-46b9-953b-d5786bdb42d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhgAAAGiCAYAAAClPb+eAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUiRJREFUeJzt3XlYVGX/P/D3gDAsCogIuBCCmEKCG4m4FyiE5cZTWppLLpepqeHXhVJxR63MVNLHXcqtLC3TUELNJdJcEFNEMRQXwAWQQFlk7t8f/jyPA6jMmYPD8n5d17ni3Oeeez4zHeXjvR2VEEKAiIiISEFGhg6AiIiIqh4mGERERKQ4JhhERESkOCYYREREpDgmGERERKQ4JhhERESkOCYYREREpDgmGERERKQ4JhhERESkOCYYREREpDgmGERERBXEoUOH8NZbb6F+/fpQqVTYuXPnc19z8OBBtG7dGmq1Gm5ubtiwYUOJOhEREWjUqBHMzMzg4+OD48ePKx98MUwwiIiIKojc3Fy0aNECERERZaqfnJyMHj164LXXXkNcXBwmTJiA4cOHY+/evVKdbdu2ISQkBGFhYTh16hRatGiBgIAA3Lp1q7w+BgBAxYedERERVTwqlQo7duxA7969n1pnypQp2L17N/7++2+prH///sjKykJUVBQAwMfHB6+++iqWL18OANBoNHBycsJHH32EqVOnllv87MEgIiIqR/n5+cjOztY68vPzFWk7NjYW/v7+WmUBAQGIjY0FABQUFODkyZNadYyMjODv7y/VKS81yrV1Hew2aWroEIioggoPXGXoEKiCObKrS7m2r+TvpL8+fRezZs3SKgsLC8PMmTP1bjstLQ0ODg5aZQ4ODsjOzsaDBw+QmZmJoqKiUutcuHBB7/d/lgqTYBAREVUUKhOVYm2FhoYiJCREq0ytVivWfkXFBIOIiKgYoxrKJRhqtbrcEgpHR0ekp6drlaWnp8PKygrm5uYwNjaGsbFxqXUcHR3LJabHOAeDiIiokvL19UVMTIxWWXR0NHx9fQEApqamaNOmjVYdjUaDmJgYqU55YQ8GERFRMSoTw/z7OycnB0lJSdJ5cnIy4uLiYGtri5deegmhoaG4ceMGIiMjAQCjRo3C8uXLMXnyZHzwwQfYv38/vvvuO+zevVtqIyQkBIMHD4a3tzfatm2LJUuWIDc3F0OHDi3Xz8IEg4iIqBglh0h0ceLECbz22mvS+eO5G4MHD8aGDRuQmpqKlJQU6bqLiwt2796Njz/+GF999RUaNmyINWvWICAgQKrTr18/3L59GzNmzEBaWhpatmyJqKioEhM/lVZh9sHgKhIiehquIqHiynsVSbRDc8Xa6pb+9/MrVUHswSAiIipGyVUk1RUTDCIiomIMNURSlXAVCRERESmOPRhERETFcIhEf0wwiIiIiuEQif44REJERESKYw8GERFRMSpj9mDoiwkGERFRMUZMMPSmU4Lx888/l7luz549dQ6GiIioIlAZMcHQl04JRu/evbXOVSoVntwIVKX63/+QoqIi/SIjIiKiSkunSZ4ajUY69u3bh5YtW+LXX39FVlYWsrKysGfPHrRu3RpRUVHlFS8REVG5UxkbKXZUV7LnYEyYMAErV65Ex44dpbKAgABYWFhg5MiRSEhIUCRAIiKiF41zMPQnO7W6fPkybGxsSpRbW1vjypUreoRERERElZ3sBOPVV19FSEgI0tPTpbL09HRMmjQJbdu2VSQ4IiIiQ1AZqRQ7qivZQyTr1q1Dnz598NJLL8HJyQkAcO3aNTRp0gQ7d+5UKj4iIqIXjkMk+pOdYLi5uSE+Ph7R0dG4cOECAMDd3R3+/v5aq0mIiIio+tFroy2VSoXu3bujc+fOUKvVTCyIiKhK4E6e+pM9B0Oj0WDOnDlo0KABatasieTkZADA9OnTsXbtWsUCJCIietFURkaKHdWV7E8+d+5cbNiwAYsWLYKpqalU3rx5c6xZs0aR4IiIiKhykp1gREZGYtWqVRgwYACMjY2l8hYtWkhzMoiIiCojriLRn+w5GDdu3ICbm1uJco1Gg8LCQr2CIiIiMiSuItGf7B4MDw8PHD58uET59u3b0apVK72CIiIiMiT2YOhPdg/GjBkzMHjwYNy4cQMajQY//vgjEhMTERkZiV9++UXJGImIiKiSkd2D0atXL+zatQu//fYbLC0tMWPGDCQkJGDXrl3o1q2bkjESERG9UFxFoj+99sHo1KkToqOjlYqFiIioQqjOQxtKqb6pFREREZUbnXowbG1tcfHiRdjZ2aF27drP3LkzIyND7+CIiIgMgatI9KdTgvHll1+iVq1aAIAlS5aURzxEREQGxyES/emUYAwePLjUn4mIiIiepFOCkZ2dXea6VlZWOgdDRERUEVTn1R9K0SnBsLGxKfMTU4uKimQFREREZGgcItGfTgnGgQMHpJ+vXLmCqVOnYsiQIfD19QUAxMbGYuPGjQgPD1c2SiIiIqpUdEowunTpIv08e/ZsLF68GO+++65U1rNnT3h6emLVqlWco0FERJUWezD0J3uQKTY2Ft7e3iXKvb29cfz4cb2CIiIiMiQ+i0R/shMMJycnrF69ukT5mjVr4OTkpFdQREREhsStwvUn+5N/+eWXWLZsGTw9PTF8+HAMHz4cXl5eWLZsGb788kslYyQiIqpWIiIi0KhRI5iZmcHHx+eZIwNdu3aFSqUqcfTo0UOqM2TIkBLXAwMDy/UzyH4WSVBQEC5evIgVK1bgwoULAIC33noLo0aNYg8GERFVaobcyXPbtm0ICQnBypUr4ePjgyVLliAgIACJiYmwt7cvUf/HH39EQUGBdH737l20aNECb7/9tla9wMBArF+/XjpXq9Xl9yGg58POnJycMH/+fKViISIiqhAMOXdi8eLFGDFiBIYOHQoAWLlyJXbv3o1169Zh6tSpJerb2tpqnW/duhUWFhYlEgy1Wg1HR8fyC7wY2QnGoUOHnnm9c+fOcpsmIiKqMvLz85Gfn69VplarS+1BKCgowMmTJxEaGiqVGRkZwd/fH7GxsWV6v7Vr16J///6wtLTUKj948CDs7e1Ru3ZtvP7665g7dy7q1Kkj4xOVjewEo2vXriXKntyEixttERFRZaXk5Mzw8HDMmjVLqywsLAwzZ84sUffOnTsoKiqCg4ODVrmDg4M0HeFZjh8/jr///htr167VKg8MDETfvn3h4uKCy5cv45NPPsEbb7yB2NhYGBsb6/6hykB2gpGZmal1XlhYiNOnT2P69OmYN2+e3oEREREZipJDJKGhoQgJCdEqK6/5D2vXroWnpyfatm2rVd6/f3/pZ09PT3h5eaFx48Y4ePAg/Pz8yiUW2QmGtbV1ibJu3brB1NQUISEhOHnypF6BERERVQVPGw4pjZ2dHYyNjZGenq5Vnp6e/tz5E7m5udi6dStmz5793PdxdXWFnZ0dkpKSyi3BUHyBroODAxITE5VuloiI6IUx1EZbpqamaNOmDWJiYqQyjUaDmJgY6bEcT/P9998jPz8fAwcOfO77XL9+HXfv3kW9evV0ik8Xsnsw4uPjtc6FEEhNTcWCBQvQsmVLfeMiIiIyGENukBUSEoLBgwfD29sbbdu2xZIlS5CbmyutKhk0aBAaNGhQ4rlfa9euRe/evUtM3MzJycGsWbMQHBwMR0dHXL58GZMnT4abmxsCAgLK7XPITjBatmwJlUoFIYRWebt27bBu3Tq9AyMiIqqO+vXrh9u3b2PGjBlIS0tDy5YtERUVJU38TElJgVGxBCgxMRFHjhzBvn37SrRnbGyM+Ph4bNy4EVlZWahfvz66d++OOXPmlOteGCpRPEMoo6tXr2qdGxkZoW7dujAzM5MVyG6TprJeR0RVX3jgKkOHQBXMkV1dnl9JD9dGByvWltPXPyjWVmUiuw/o999/h6OjI5ydneHs7AwnJyeYmZmhoKAAkZGRSsZIRET0QvFZJPqT/cmHDh2Ke/fulSj/999/pXEiIiKiSkmlUu6opmQnGEIIrY21Hrt+/XqpS1iJiIio+tB5kmerVq2kJ7H5+fmhRo3/NVFUVITk5ORyf0JbVWPb0RuuE4fBunVzmNW3x4ng0Uj/Oeb5L6QqifcDlaazrx16v1EPTRvXgrWVCYaMO4Gk5FxDh1VlGfJZJFWFzglG7969AQBxcXEICAhAzZo1pWumpqZo1KgRgoOVmxxTHRhbWiA7PhHXNvwA7+0Rhg6HDIz3A5XG3MwI8eezsf/IbUz9iJPiy1t1njuhFJ0TjLCwMABAo0aN0K9fP9mrRuh/bu89hNt7n/3wOKo+eD9QafYeuAUAcLQv30dsEylF9j4YgwcPln7Oy8vDtm3bkJubi27duqFJkyaKBEdERGQIHCLRn84JRkhICAoLC7Fs2TIAjx4t265dO5w/fx4WFhaYPHkyoqOjn7mlaWmPri0UGpio2CVFRESGxyES/en8De7btw/dunWTzjdt2oSUlBRcunQJmZmZePvttzF37txnthEeHg5ra2ut4ztNhu7RExFVQd262GPfdx2lw8uDK/Oo8tG5ByMlJQUeHh7S+b59+/Cf//wHzs7OAIDx48cjKCjomW2U9uja/bZtdA2FiKhKOnL8Ls5fPCGd375bYMBoqicOkehP5wTDyMhI6/kjf/75J6ZPny6d29jYIDMz85ltlPboWg6PEBE98uBBEW48KDJ0GNUaEwz96fxb3d3dHbt27QIAnDt3DikpKXjttdek61evXpUeyEJlY2xpAasWzWDVohkAwMKlIaxaNIOZU/k9RpcqLt4PVJpaNWvAzcUSjZwsAQAvNbCAm4slbG1MDBwZUel07sGYPHky+vfvj927d+PcuXMICgqCi4uLdH3Pnj1o27atokFWddZtmsM35hvp3OPzTwAA1yJ/RPywUEOFRQbC+4FK09GnDj6d0Ew6nz3l0VD1us1XsG7L1ae9jOTiJE+96Zxg9OnTB3v27MEvv/yC7t2746OPPtK6bmFhgdGjRysWYHWQceg4nyZLEt4PVJpfY9Lxa0y6ocOoNkp7FAbpRtY+GH5+fvDz8yv12uONuB4bPXo0Zs+eDTs7OzlvRURE9MJxmar+yv0b/Pbbb5GdnV3eb0NEREQViOydPMvqyRUnRERElQFXkeiv3BMMIiKiSodDJHrjN0hERESKYw8GERFRMRwi0R8TDCIiomJU3F1ab+X+DQ4cOBBWVlbl/TZERERUgchOMKKionDkyBHpPCIiAi1btsR7772n9SySFStWcA8MIiKqXIxUyh3VlOwEY9KkSdL+FmfPnsXEiRMRFBSE5OTkEk9KJSIiqkxURkaKHdWV7DkYycnJ0mPbf/jhB7z55puYP38+Tp069dzHtRMREVVknOSpP9mplampKe7fvw8A+O2339C9e3cAgK2tLXfuJCIiquZk92B06NABISEh6NChA44fP45t27YBAC5evIiGDRsqFiAREdELx1UkepP9DUZERMDExATbt2/HihUr0KBBAwDAr7/+isDAQMUCJCIietFURirFjupKVg/Gw4cPcfDgQaxevRqOjo5a17788ktFAiMiIqLKS1YPRo0aNTBq1Cjk5+crHQ8REZHhGRkpd1RTsj9527Ztcfr0aSVjISIiqhBUKpViR3Ule5Ln6NGjMXHiRFy/fh1t2rSBpaWl1nUvLy+9gyMiIqLKSXaC0b9/fwDAuHHjpDKVSgUhBFQqFYqKivSPjoiIyBCq8dCGUvTaaIuIiKgqqs6rP5QiO8FwdnZWMg4iIiKqQmQnGJGRkc+8PmjQILlNExERGZaBN9qKiIjAZ599hrS0NLRo0QLLli1D27ZtS627YcMGDB06VKtMrVYjLy9POhdCICwsDKtXr0ZWVhY6dOiAFStWoEmTJuX2GWQnGOPHj9c6LywsxP3792FqagoLCwsmGEREVHkZcIhk27ZtCAkJwcqVK+Hj44MlS5YgICAAiYmJsLe3L/U1VlZWSExMlM6Lr15ZtGgRli5dio0bN8LFxQXTp09HQEAAzp8/DzMzs3L5HLJTtMzMTK0jJycHiYmJ6NixI7Zs2aJkjERERC+USmWk2KGrxYsXY8SIERg6dCg8PDywcuVKWFhYYN26dc+IVwVHR0fpcHBwkK4JIbBkyRJMmzYNvXr1gpeXFyIjI3Hz5k3s3LlTztdTJor2ATVp0gQLFiwo0btBRERUXeXn5yM7O1vreNpGlQUFBTh58iT8/f2lMiMjI/j7+yM2Nvap75GTkwNnZ2c4OTmhV69eOHfunHQtOTkZaWlpWm1aW1vDx8fnmW3qS/FBpho1auDmzZtKN0tERPTiGKkUO8LDw2Ftba11hIeHl/q2d+7cQVFRkVYPBAA4ODggLS2t1Nc0bdoU69atw08//YRvv/0WGo0G7du3x/Xr1wFAep0ubSpB9hyMn3/+WetcCIHU1FQsX74cHTp00DswIiIiQ1EpuA9GaGgoQkJCtMrUarVi7fv6+sLX11c6b9++Pdzd3fHf//4Xc+bMUex9dCU7wejdu7fWuUqlQt26dfH666/jiy++0DcuIiKiKkGtVpc5obCzs4OxsTHS09O1ytPT00s8XPRpTExM0KpVKyQlJQGA9Lr09HTUq1dPq82WLVuWqU05ZKdoGo1G6ygqKkJaWho2b96s9QGIiIgqHZVKuUMHpqamaNOmDWJiYqQyjUaDmJgYrV6KZykqKsLZs2el38UuLi5wdHTUajM7OxvHjh0rc5tyyO7BeJIQAkDJZTFERESVkgG3Cg8JCcHgwYPh7e2Ntm3bYsmSJcjNzZX2uhg0aBAaNGggzeOYPXs22rVrBzc3N2RlZeGzzz7D1atXMXz4cACPfjdPmDABc+fORZMmTaRlqvXr1y8xGqEkvRKMyMhIfPbZZ7h06RIA4OWXX8akSZPw/vvvKxIcERFRddOvXz/cvn0bM2bMQFpaGlq2bImoqChpkmZKSgqMnkiAMjMzMWLECKSlpaF27dpo06YN/vjjD3h4eEh1Jk+ejNzcXIwcORJZWVno2LEjoqKiym0PDABQicfdDzpavHgxpk+fjrFjx0qTOo8cOYKIiAjMnTsXH3/8sU7t7TZpKicMIqoGwgNXGToEqmCO7OpSru3f3zhbsbYsBs9QrK3KRHYPxrJly7BixQqtHTt79uyJV155BTNnztQ5wSAiIqoolFxFUl3J/gZTU1PRvn37EuXt27dHamqqXkERERFR5SY7wXBzc8N3331Xonzbtm3l+vAUIiKicqcyUu6opmQPkcyaNQv9+vXDoUOHpDkYR48eRUxMTKmJBxERUaVhwIedVRWyE4zg4GAcO3YMX375pfSwFHd3dxw/fhytWrVSKj4iIqIXTs5DykibzglGdna29HOTJk3w9ddfl1rHyspKv8iIiIio0tI5wbCxsSnThlpFRUWyAiIiIjI4DpHoTecE48CBA9LPQggEBQVhzZo1aNCggaKBERERGQyHSPSmc4LRpYv25ibGxsZo164dXF1dFQuKiIiIKjdFnkVCRERUpfDZWnpjgkFERFQcd/LUmyLfIJ+iSkRERE/SuQejb9++Wud5eXkYNWoULC0ttcp//PFH/SIjIiIyFE7y1JvOCYa1tbXW+cCBAxULhoiIqELgMlW96ZxgrF+/vjziICIioiqEkzyJiIiK4xCJ3phgEBERFcfFC3pjgkFERFQcl6nqjd8gERERKY49GERERMVxiERvTDCIiIiK4yRPvfEbJCIiIsWxB4OIiKg4TvLUGxMMIiKi4jgHQ29M0YiIiEhx7MEgIiIqjpM89cYEg4iIqDgOkeiNKRoREREpjj0YRERExXEVid6YYBARERUjOESiNyYYRERExXGSp974DRIREZHi2INBRERUHHsw9MYEg4iIqBjOwdAfUzQiIiJSHHswiIiIiuMQid74DRIRERWnUil3yBAREYFGjRrBzMwMPj4+OH78+FPrrl69Gp06dULt2rVRu3Zt+Pv7l6g/ZMgQqFQqrSMwMFBWbGXFBIOIiKgC2bZtG0JCQhAWFoZTp06hRYsWCAgIwK1bt0qtf/DgQbz77rs4cOAAYmNj4eTkhO7du+PGjRta9QIDA5GamiodW7ZsKdfPwSESIiKi4hTcyTM/Px/5+flaZWq1Gmq1utT6ixcvxogRIzB06FAAwMqVK7F7926sW7cOU6dOLVF/06ZNWudr1qzBDz/8gJiYGAwaNEjrPR0dHfX9OGXGHgwiIqJihEql2BEeHg5ra2utIzw8vNT3LSgowMmTJ+Hv7y+VGRkZwd/fH7GxsWWK/f79+ygsLIStra1W+cGDB2Fvb4+mTZviww8/xN27d+V/QWXAHgwiIqJyFBoaipCQEK2yp/Ve3LlzB0VFRXBwcNAqd3BwwIULF8r0flOmTEH9+vW1kpTAwED07dsXLi4uuHz5Mj755BO88cYbiI2NhbGxsY6fqGyYYBARERWn4CqSZw2HKG3BggXYunUrDh48CDMzM6m8f//+0s+enp7w8vJC48aNcfDgQfj5+ZVLLBwiISIiKkaojBQ7dGFnZwdjY2Okp6drlaenpz93/sTnn3+OBQsWYN++ffDy8npmXVdXV9jZ2SEpKUmn+HTBBIOIiKg4Ay1TNTU1RZs2bRATEyOVaTQaxMTEwNfX96mvW7RoEebMmYOoqCh4e3s/932uX7+Ou3fvol69ejrFpwsmGERERBVISEgIVq9ejY0bNyIhIQEffvghcnNzpVUlgwYNQmhoqFR/4cKFmD59OtatW4dGjRohLS0NaWlpyMnJAQDk5ORg0qRJ+PPPP3HlyhXExMSgV69ecHNzQ0BAQLl9Ds7BICIiKkbXoQ0l9evXD7dv38aMGTOQlpaGli1bIioqSpr4mZKSAqMnltGuWLECBQUF+M9//qPVTlhYGGbOnAljY2PEx8dj48aNyMrKQv369dG9e3fMmTOnXOeGqIQQotxa18Fuk6aGDoGIKqjwwFWGDoEqmCO7upRr+//+tUextmq9GqRYW5WJ3ilaUlIS9u7diwcPHgAAKki+QkRERAYkO8G4e/cu/P398fLLLyMoKAipqakAgGHDhmHixImKBUhERPTCqYyUO6op2Z/8448/Ro0aNZCSkgILCwupvF+/foiKilIkOCIiIkNQcifP6kr2JM99+/Zh7969aNiwoVZ5kyZNcPXqVb0DIyIiospLdoKRm5ur1XPxWEZGxgvbsYyIiKhcVOOhDaXI/gY7deqEyMhI6VylUkGj0WDRokV47bXXFAmOiIjIEARUih3VlewejEWLFsHPzw8nTpxAQUEBJk+ejHPnziEjIwNHjx5VMkYiIiKqZGT3YDRv3hwXL15Ex44d0atXL+Tm5qJv3744ffo0GjdurGSMREREL5ShnkVSlcjqwSgsLERgYCBWrlyJTz/9VOmYiIiIDKsaJwZKkZVgmJiYID4+XulYiIiIKoTqvLxUKbJTtIEDB2Lt2rVKxkJERERVhOxJng8fPsS6devw22+/oU2bNrC0tNS6vnjxYr2DIyIiMoTqPHdCKbITjL///hutW7cGAFy8eFHrmopdS0REVJnx95jeZCcYBw4cUDIOIiIiqkJkJxhPun79OgCU2DaciIioMuIQif5kf4MajQazZ8+GtbU1nJ2d4ezsDBsbG8yZMwcajUbJGImIiF4o7uSpP9k9GJ9++inWrl2LBQsWoEOHDgCAI0eOYObMmcjLy8O8efMUC5KIiIgqF9kJxsaNG7FmzRr07NlTKvPy8kKDBg0wevRoJhhERFRpcYhEf7ITjIyMDDRr1qxEebNmzZCRkaFXUERERAbFVSR6k52itWjRAsuXLy9Rvnz5crRo0UKvoIiIiKhy0+tpqj169MBvv/0GX19fAEBsbCyuXbuGPXv2KBYgERHRiybk//ub/j/Z32CXLl2QmJiIPn36ICsrC1lZWejbty8SExPRqVMnJWMkIiJ6oYRKpdhRXem1D0aDBg04mZOIiKocTvLUn+xvcP369fj+++9LlH///ffYuHGjXkERERFR5SY7wQgPD4ednV2Jcnt7e8yfP1+voIiIiAyJG23pT/YQSUpKClxcXEqUOzs7IyUlRa+giIiIDIlDJPqT/Q3a29sjPj6+RPmZM2dQp04dvYIiIiKiyk12D8a7776LcePGoVatWujcuTMA4Pfff8f48ePRv39/xQIkIiJ60arz6g+lyE4w5syZgytXrsDPzw81ajxqRqPRYNCgQZyDQURElVp1njuhFNkJhqmpKbZt24a5c+ciLi4O5ubm8PT0hLOzs5LxERERUSWk1z4YANCkSRM0adIEDx8+RF5enhIxERERGRQneepP529w165d2LBhg1bZvHnzULNmTdjY2KB79+7IzMxUKj4iIqIXjstU9adzgrF48WLk5uZK53/88QdmzJiB6dOn47vvvsO1a9cwZ84cRYMkIiKiykXnBOPcuXNo3769dL59+3Z069YNn376Kfr27YsvvvgCu3btUjTIqs62oze8d6yA39XD6FGYCIeefoYOiQyI9wOVprOvHRbP9sTuTe1xZFcXuLlYGjqkKk2ojBQ7qiudP/m///6rtc/FkSNH4Of3v78AX3nlFdy8eVOZ6KoJY0sLZMcn4u9xswwdClUAvB+oNOZmRog/n40VG/8xdCjVAodI9KdzgtGgQQMkJCQAAHJycnDmzBmtHo27d+/CwsJCuQirgdt7D+Fi2BKk//SboUOhCoD3A5Vm74Fb2LD1Kk7EcY7bi2DoHoyIiAg0atQIZmZm8PHxwfHjx59Z//vvv0ezZs1gZmYGT09P7NmzR/vzCIEZM2agXr16MDc3h7+/Py5duiQrtrLS+ZO//fbbmDBhAr755huMGDECjo6OaNeunXT9xIkTaNq0qaJBEhERVRfbtm1DSEgIwsLCcOrUKbRo0QIBAQG4detWqfX/+OMPvPvuuxg2bBhOnz6N3r17o3fv3vj777+lOosWLcLSpUuxcuVKHDt2DJaWlggICCjX1Z86JxgzZszAq6++inHjxiEuLg7ffvstjI2NpetbtmzBW2+99cw28vPzkZ2drXUUCo3u0RMREZUDJYdISvudl5+f/9T3Xrx4MUaMGIGhQ4fCw8MDK1euhIWFBdatW1dq/a+++gqBgYGYNGkS3N3dMWfOHLRu3RrLly9/9FmEwJIlSzBt2jT06tULXl5eiIyMxM2bN7Fz587y+PoAyEgwzM3NERkZiczMTCQkJKBTp05a1w8cOIApU6ZI50ePHi3xRYaHh8Pa2lrr+E6TIfMjEBFVLd262GPfdx2lw8vD2tAhVTtCpVLsKO13Xnh4eKnvW1BQgJMnT8Lf318qMzIygr+/P2JjY0t9TWxsrFZ9AAgICJDqJycnIy0tTauOtbU1fHx8ntqmEvTeaOt53njjDcTFxcHV1VUqCw0NRUhIiFa9/bZtyjsUIqJK4cjxuzh/8YR0fvtugQGjIX2V9jtPrVaXWvfOnTsoKiqCg4ODVrmDgwMuXLhQ6mvS0tJKrZ+WliZdf1z2tDrlodwTDCFEiTK1Wl3iyzWpxkt5iIie9OBBEW48KDJ0GNWaEMqt/ijtd151UO4JBj2fsaUFLN1eks4tXBrCqkUzFGTcQ961VANGRobA+4FKU6tmDTjUVcPO9tEvqpcaPFqtl5FZgIysQkOGViUJ3WcQKMLOzg7GxsZIT0/XKk9PT4ejo2Opr3F0dHxm/cf/TU9PR7169bTqtGzZUsHotbHboAKwbtMcnU78hE4nfgIAeHz+CTqd+Akvzxxn4MjIEHg/UGk6+tTBhqXe+HymJwBg9hQPbFjqjd5v1DdwZKQkU1NTtGnTBjExMVKZRqNBTEwMfH19S32Nr6+vVn0AiI6Oluq7uLjA0dFRq052djaOHTv21DaVwB6MCiDj0HHsNuHSXnqE9wOV5teYdPwak/78iqQIQ26QFRISgsGDB8Pb2xtt27bFkiVLkJubi6FDhwIABg0ahAYNGkgTRcePH48uXbrgiy++QI8ePbB161acOHECq1atAgCoVCpMmDABc+fORZMmTeDi4oLp06ejfv366N27d7l9jnJPMFSq6ruLGRERVU6GTDD69euH27dvY8aMGUhLS0PLli0RFRUlTdJMSUmBkdH/BiDat2+PzZs3Y9q0afjkk0/QpEkT7Ny5E82bN5fqTJ48Gbm5uRg5ciSysrLQsWNHREVFwczMrNw+h0qUNgtTQbVq1cKZM2e0VpGUhv9iI6KnCQ9cZegQqII5sqtLubafePmaYm01beykWFuVSbn3YPz777/l/RZERESKqs7PEFGK7ATj7t27mDFjBg4cOIBbt25Bo9HeiTMjgxtnERFR5cQEQ3+yE4z3338fSUlJGDZsGBwcHDjXgoiIqgwl98GormQnGIcPH8aRI0fQokULJeMhIiKiKkB2gtGsWTM8ePBAyViIiIgqBA6R6E/2Rltff/01Pv30U/z++++4e/duiSfFERERVVZKPk21upLdg2FjY4Ps7Gy8/vrrWuVCCKhUKhQVcR99IiKi6kp2gjFgwACYmJhg8+bNnORJRERVSnXueVCK7ATj77//xunTp9G0KTfIIiKiqoWrSPQnew6Gt7c3rl1TbqczIiIiqjpk92B89NFHGD9+PCZNmgRPT0+YmJhoXffy8tI7OCIiIkPQcIhEb7ITjH79+gEAPvjgA6lMpVJxkicREVV6nIOhP9kJRnJyspJxEBERURUiO8FwdnZWMg4iIqIKg5M89af301TPnz+PlJQUFBQUaJX37NlT36aJiIgMgkMk+pOdYPzzzz/o06cPzp49K829ACDth8E5GEREVFmxB0N/spepjh8/Hi4uLrh16xYsLCxw7tw5HDp0CN7e3jh48KCCIRIREVFlI7sHIzY2Fvv374ednR2MjIxgZGSEjh07Ijw8HOPGjcPp06eVjJOIiOiF4RCJ/mT3YBQVFaFWrVoAADs7O9y8eRPAo8mfiYmJykRHRERkAEKoFDuqK9k9GM2bN8eZM2fg4uICHx8fLFq0CKampli1ahVcXV2VjJGIiIgqGdkJxrRp05CbmwsAmD17Nt5880106tQJderUwbZt2xQLkIiI6EXTGDqAKkB2ghEQECD97ObmhgsXLiAjIwO1a9fmk1WJiKhSq85DG0qRPQfj9u3bJcpsbW2hUqlw9uxZvYIiIiKiyk12guHp6Yndu3eXKP/888/Rtm1bvYIiIiIyJAGVYkd1JTvBCAkJQXBwMD788EM8ePAAN27cgJ+fHxYtWoTNmzcrGSMREdELxVUk+pOdYEyePBmxsbE4fPgwvLy84OXlBbVajfj4ePTp00fJGImIiKiSkZ1gAI8mdzZv3hxXrlxBdnY2+vXrB0dHR6ViIyIiMggOkehPdoJx9OhReHl54dKlS4iPj8eKFSvw0UcfoV+/fsjMzFQyRiIiohdKI5Q7qivZCcbrr7+Ofv364c8//4S7uzuGDx+O06dPIyUlBZ6enkrGSERE9EKxB0N/svfB2LdvH7p06aJV1rhxYxw9ehTz5s3TOzAiIiKqvHTuwQgKCsK9e/ek5GLBggXIysqSrmdmZmLLli2KBUhERPSicRWJ/nROMPbu3Yv8/HzpfP78+cjIyJDOHz58yIedERFRpSaEckd1pXOCIYp9W8XPiYiIiGTPwSAiIqqqNNV4cqZSdE4wVCpViYeZ8eFmRERUlVTnuRNKkTVEMmTIEPTt2xd9+/ZFXl4eRo0aJZ1/8MEH5REnERERPSEjIwMDBgyAlZUVbGxsMGzYMOTk5Dyz/kcffYSmTZvC3NwcL730EsaNG4d79+5p1XvckfDksXXrVp3j07kHY/DgwVrnAwcOLFFn0KBBOgdCRERUUVSG6YUDBgxAamoqoqOjUVhYiKFDh2LkyJFPfR7YzZs3cfPmTXz++efw8PDA1atXMWrUKNy8eRPbt2/Xqrt+/XoEBgZK5zY2NjrHpxIVZJbmbpOmhg6BiCqo8MBVhg6BKpgju7o8v5Ie9p0pUKyt7i1MFWvrsYSEBHh4eOCvv/6Ct7c3ACAqKgpBQUG4fv066tevX6Z2vv/+ewwcOBC5ubmoUeNRn4NKpcKOHTvQu3dvvWLU61kkRERE9Gz5+fnIzs7WOp7c7kGO2NhY2NjYSMkFAPj7+8PIyAjHjh0rczv37t2DlZWVlFw8NmbMGNjZ2aFt27ZYt26drBWjTDCIiIiKUfJZJOHh4bC2ttY6wsPD9YovLS0N9vb2WmU1atSAra0t0tLSytTGnTt3MGfOHIwcOVKrfPbs2fjuu+8QHR2N4OBgjB49GsuWLdM5Ri5TJSIiKkbJVSShoaEICQnRKlOr1aXWnTp1KhYuXPjM9hISEvSOKTs7Gz169ICHhwdmzpypdW369OnSz61atUJubi4+++wzjBs3Tqf3YIJBRERUjJKzE9Vq9VMTiuImTpyIIUOGPLOOq6srHB0dcevWLa3yhw8fIiMjA46Ojs98/b///ovAwEDUqlULO3bsgImJyTPr+/j4YM6cOcjPzy/z5wCYYBAREVUYdevWRd26dZ9bz9fXF1lZWTh58iTatGkDANi/fz80Gg18fHye+rrs7GwEBARArVbj559/hpmZ2XPfKy4uDrVr19YpuQCYYBAREZVQ0XfydHd3R2BgIEaMGIGVK1eisLAQY8eORf/+/aUVJDdu3ICfnx8iIyPRtm1bZGdno3v37rh//z6+/fZbacIp8CixMTY2xq5du5Ceno527drBzMwM0dHRmD9/Pv7v//5P5xiZYBARERVTMTZweLZNmzZh7Nix8PPzg5GREYKDg7F06VLpemFhIRITE3H//n0AwKlTp6QVJm5ublptJScno1GjRjAxMUFERAQ+/vhjCCHg5uaGxYsXY8SIETrHx30wiKjC4z4YVFx574Ox6+RDxdp6q031/Ld89fzUREREz8BnkeiPCQYREVExmgrRt1+5caMtIiIiUhx7MIiIiIqpGLMTKzcmGERERMWICr5MtTLgEAkREREpjj0YRERExXCSp/6YYBARERXDORj6qzAJBjfSIaKnCY0a+fxKVM0klmvrTDD0xzkYREREpLgK04NBRERUUWi4k6femGAQEREVwyES/XGIhIiIiBTHHgwiIqJi2IOhPyYYRERExXAfDP1xiISIiIgUxx4MIiKiYgRXkeiNCQYREVExnIOhPw6REBERkeLYg0FERFQMJ3nqjwkGERFRMRwi0R8TDCIiomKYYOiPczCIiIhIcezBICIiKoZzMPTHBIOIiKgYDpHoj0MkREREpDj2YBARERWj0Rg6gsqPCQYREVExHCLRH4dIiIiISHGKJBjZ2dnYuXMnEhISlGiOiIjIoIRQ7qiuZCUY77zzDpYvXw4AePDgAby9vfHOO+/Ay8sLP/zwg6IBEhERvWgaodxRXclKMA4dOoROnToBAHbs2AEhBLKysrB06VLMnTtX0QCJiIio8pGVYNy7dw+2trYAgKioKAQHB8PCwgI9evTApUuXFA2QiIjoRRNCKHZUV7ISDCcnJ8TGxiI3NxdRUVHo3r07ACAzMxNmZmaKBkhERPSicQ6G/mQtU50wYQIGDBiAmjVrwtnZGV27dgXwaOjE09NTyfiIiIheOO6DoT9ZPRijR4/Gn3/+iXXr1uHIkSMwMnrUjKurK+dgEBERvQAZGRkYMGAArKysYGNjg2HDhiEnJ+eZr+natStUKpXWMWrUKK06KSkp6NGjBywsLGBvb49Jkybh4cOHOsencw9GYWEhmjVrhl9++QV9+vTRutajRw+dAyAiIqpoKsPQxoABA5Camoro6GgUFhZi6NChGDlyJDZv3vzM140YMQKzZ8+Wzi0sLKSfi4qK0KNHDzg6OuKPP/5AamoqBg0aBBMTE8yfP1+n+HROMExMTJCXl6fry4iIiCqNir68NCEhAVFRUfjrr7/g7e0NAFi2bBmCgoLw+eefo379+k99rYWFBRwdHUu9tm/fPpw/fx6//fYbHBwc0LJlS8yZMwdTpkzBzJkzYWpqWuYYZQ2RjBkzBgsXLpTVZUJERFSd5OfnIzs7W+vIz8/Xq83Y2FjY2NhIyQUA+Pv7w8jICMeOHXvmazdt2gQ7Ozs0b94coaGhuH//vla7np6ecHBwkMoCAgKQnZ2Nc+fO6RSjrEmef/31F2JiYrBv3z54enrC0tJS6/qPP/4op1kiIqIKQckhkvDwcMyaNUurLCwsDDNnzpTdZlpaGuzt7bXKatSoAVtbW6SlpT31de+99x6cnZ1Rv359xMfHY8qUKUhMTJR+b6elpWklFwCk82e1WxpZCYaNjQ2Cg4PlvJSIiKjCEwqOkYSGhiIkJESrTK1Wl1p36tSpWLhw4TPb0+exHCNHjpR+9vT0RL169eDn54fLly+jcePGststjawEY/369YoGQUREVFWp1eqnJhTFTZw4EUOGDHlmHVdXVzg6OuLWrVta5Q8fPkRGRsZT51eUxsfHBwCQlJSExo0bw9HREcePH9eqk56eDgA6tQvwce1EREQlGGqSZ926dVG3bt3n1vP19UVWVhZOnjyJNm3aAAD2798PjUYjJQ1lERcXBwCoV6+e1O68efNw69YtaQgmOjoaVlZW8PDw0OmzyEowXFxcoFKpnnr9n3/+kdMsERFRhVDRl6m6u7sjMDAQI0aMwMqVK1FYWIixY8eif//+0gqSGzduwM/PD5GRkWjbti0uX76MzZs3IygoCHXq1EF8fDw+/vhjdO7cGV5eXgCA7t27w8PDA++//z4WLVqEtLQ0TJs2DWPGjClzL8xjsnfyfFJhYSFOnz6NqKgoTJo0SU6TREREpINNmzZh7Nix8PPzg5GREYKDg7F06VLpemFhIRITE6VVIqampvjtt9+wZMkS5ObmwsnJCcHBwZg2bZr0GmNjY/zyyy/48MMP4evrC0tLSwwePFhr34yyUgkFn8QSERGBEydOyJqj0fGt35UKg4iqmNCokc+vRNVKj8LEcm0//LsixdoKfcdYsbYqE1n7YDzNG2+8gR9++EHJJomIiF44PuxMf4pO8ty+fbv0GHciIqLKqjonBkqRlWC0atVKa5KnEAJpaWm4ffs2vv76a8WCIyIiospJVoLRu3dvrXMjIyPUrVsXXbt2RbNmzZSIi4iIyGA07MLQm6wEIywsTOk4iIiIKgyhMXQElZ/sORhFRUXYuXOntGXpK6+8gp49e8LYuHrOliUiIqL/kZVgJCUlISgoCDdu3EDTpk0BPHqYi5OTE3bv3q34fuZEREQvkoI7OFRbspapjhs3Do0bN8a1a9dw6tQpnDp1CikpKXBxccG4ceOUjpGIiOiF0miUO6orWT0Yv//+O/7880+tJal16tTBggUL0KFDB8WCIyIiospJVoKhVqvx77//lijPycmBqamp3kEREREZEodI9CdriOTNN9/EyJEjcezYMQghIITAn3/+iVGjRqFnz55Kx0hERPRCaYRyR3UlK8FYunQpGjduDF9fX5iZmcHMzAwdOnSAm5sbvvrqK6VjJCIiokpG1hCJjY0NfvrpJ1y6dAkXLlwA8OjRsW5ubooGR0REZAiiOnc9KESvZ5E0adIETZo0USoWIiKiCoFTMPSnU4IREhJSpnqLFy+WFQwREVFFoGEPht50SjBOnz6tdX7kyBG0adMG5ubmUtmTD0EjIiKi6kmnBOPAgQNa57Vq1cLmzZvh6uqqaFBERESGxGWq+tNrDgYREVFVxIed6U/WMlUiIiKiZ2EPRgXS2dcOvd+oh6aNa8HaygRDxp1AUnKuocMiA+H9QI/ZdvSG68RhsG7dHGb17XEieDTSf44xdFhVmoZDJHrTKcGIj4/XOhdC4MKFC8jJydEq9/Ly0j+yasjczAjx57Ox/8htTP2oqaHDIQPj/UCPGVtaIDs+Edc2/ADv7RGGDqda4BwM/emUYLRs2RIqlUrri3/zzTcBQCpXqVQoKipSNspqYu+BWwAAR3u1gSOhioD3Az12e+8h3N57yNBhEOlEpwQjOTm5vOIgIiKqMLgPhv50SjCcnZ11anz06NGYPXs27OzstMrz8/ORn5+vVaYpKoCRMZ/ESkREhscREv2V6yqSb7/9FtnZ2SXKw8PDYW1trXVcT9pUnqFUON262GPfdx2lw8vD2tAhkQHxfiCqWIRGKHZUV+W6iuRpk2RCQ0NLbDse2P9YeYZS4Rw5fhfnL56Qzm/fLTBgNGRovB+IqKoxyDJVtVoNtVp74lp1Gx558KAINx5wMiw9wvuBqGLhMlX9cR+MCqRWzRpwqKuGne2j5OulBhYAgIzMAmRkFRoyNDIA3g/0mLGlBSzdXpLOLVwawqpFMxRk3EPetVQDRlZ1VeehDaUwwahAOvrUwacTmknns6d4AADWbb6CdVuuGiosMhDeD/SYdZvm8I35Rjr3+PwTAMC1yB8RPyzUUGERPRMTjArk15h0/BqTbugwqILg/UCPZRw6jt0m3GztRWIPhv7KNcEYOHAgrKysyvMtiIiIFMf8Qn+yE4zMzEysXbsWCQkJAAB3d3d88MEHsLW1leqsWLFC/wiJiIio0pG1D8ahQ4fg4uKCpUuXIjMzE5mZmVi2bBlcXFxw6BC3syUiosqN+2DoT1YPxpgxY/DOO+9gxYoVMDY2BgAUFRVh9OjRGDNmDM6ePatokERERC8SH3amP1k9GElJSZg4caKUXACAsbExQkJCkJSUpFhwREREVDnJSjBat24tzb14UkJCAlq0aKF3UERERIak0QjFjvKSkZGBAQMGwMrKCjY2Nhg2bBhycnKeWv/KlStQqVSlHt9//71Ur7TrW7du1Tk+WUMk48aNw/jx45GUlIR27doBAP78809ERERgwYIFiI+Pl+p6eXnJeQsiIiKDqQxDJAMGDEBqaiqio6NRWFiIoUOHYuTIkdi8eXOp9Z2cnJCaqr0x26pVq/DZZ5/hjTfe0Cpfv349AgMDpXMbGxud45OVYLz77rsAgMmTJ5d6TaVSQQgBlUqFoiJuf0xERJVLRZ+cmZCQgKioKPz111/w9vYGACxbtgxBQUH4/PPPUb9+/RKvMTY2hqOjo1bZjh078M4776BmzZpa5TY2NiXq6kpWgpGcnKzXmxIREVUX+fn5yM/P1yor7ZlcuoiNjYWNjY2UXACAv78/jIyMcOzYMfTp0+e5bZw8eRJxcXGIiIgocW3MmDEYPnw4XF1dMWrUKAwdOhQqlUqnGGUlGM7OznJeRkREVCko2YMRHh6OWbNmaZWFhYVh5syZsttMS0uDvb29VlmNGjVga2uLtLS0MrWxdu1auLu7o3379lrls2fPxuuvvw4LCwvs27cPo0ePRk5ODsaNG6dTjLImeQLAN998gw4dOqB+/fq4evXRcxGWLFmCn376SW6TREREFYJGCMWO0NBQ3Lt3T+sIDS39GTJTp0596kTMx8eFCxf0/nwPHjzA5s2bMWzYsBLXpk+fjg4dOqBVq1aYMmUKJk+ejM8++0zn95CVYKxYsQIhISEICgpCVlaWNM/CxsYGS5YskdMkERFRlaRWq2FlZaV1PG14ZOLEiUhISHjm4erqCkdHR9y6dUvrtQ8fPkRGRkaZ5k5s374d9+/fx6BBg55b18fHB9evXy8xzPM8soZIli1bhtWrV6N3795YsGCBVO7t7Y3/+7//k9MkERFRhWGoSZ5169ZF3bp1n1vP19cXWVlZOHnyJNq0aQMA2L9/PzQaDXx8fJ77+rVr16Jnz55leq+4uDjUrl1b5zkjsid5tmrVqkS5Wq1Gbm6unCaJiIgqjIq+TNXd3R2BgYEYMWIEVq5cicLCQowdOxb9+/eXVpDcuHEDfn5+iIyMRNu2baXXJiUl4dChQ9izZ0+Jdnft2oX09HS0a9cOZmZmiI6Oxvz582V1HshKMFxcXBAXF1dismdUVBTc3d3lNElEREQ62LRpE8aOHQs/Pz8YGRkhODgYS5cula4XFhYiMTER9+/f13rdunXr0LBhQ3Tv3r1EmyYmJoiIiMDHH38MIQTc3NywePFijBgxQuf4ZCUYISEhGDNmDPLy8iCEwPHjx7FlyxaEh4djzZo1cpokIiKqMMpzB06l2NraPnVTLQBo1KhRqT0x8+fPx/z580t9TWBgoNYGW/qQlWAMHz4c5ubmmDZtGu7fv4/33nsP9evXx1dffYX+/fsrEhgREZGhVPSNtioDWQkG8GiL0gEDBuD+/fvIyckpsR6XiIiIqi/Z+2A8fPgQv/32G7755huYm5sDAG7evPnMB60QERFVBkIIxY7qSlYPxtWrVxEYGIiUlBTk5+ejW7duqFWrFhYuXIj8/HysXLlS6TiJiIheGKHRGDqESk9WD8b48ePh7e2NzMxMqfcCAPr06YOYmBjFgiMiIjKEyvC49opOVg/G4cOH8ccff8DU1FSrvFGjRrhx44YigREREVHlJSvB0Gg0pT6G/fr166hVq5beQRERERlSdZ47oRRZQyTdu3fXeuaISqVCTk4OwsLCEBQUpFRsREREBiE0QrGjupLVg/HFF18gICAAHh4eyMvLw3vvvYdLly7Bzs4OW7ZsUTpGIiIiqmRkJRgNGzbEmTNnsHXrVsTHxyMnJwfDhg3DgAEDtCZ9EhERVUbVuedBKbI32qpRowYGDhyoZCxEREQVgkZwmaq+ypxg/Pzzz2VutGfPnrKCISIioqqhzAlG7969y1RPpVKVusKEiIiosuAQif7KnGBouKsZERFVE0ww9KfTMtXY2Fj88ssvWmWRkZFwcXGBvb09Ro4cifz8fEUDJCIiospHpwRj1qxZOHfunHR+9uxZDBs2DP7+/pg6dSp27dqF8PBwxYMkIiJ6kfiwM/3ptIrkzJkzmDt3rnS+detW+Pj4YPXq1QAAJycnhIWFYebMmYoGSURE9CJxWoD+dEowMjMz4eDgIJ3//vvveOONN6TzV199FdeuXVMuOiIiIgPgHAz96TRE4uDggOTkZABAQUEBTp06hXbt2knX//33X5iYmCgbIREREVU6OvVgBAUFYerUqVi4cCF27twJCwsLdOrUSboeHx+Pxo0bKx4kERHRiyS40ZbedEow5syZg759+6JLly6oWbMmNm7cqPXI9nXr1qF79+6KB0lERPQicYhEfzolGHZ2djh06BDu3buHmjVrwtjYWOv6999/j5o1ayoaIBEREVU+sp5FYm1tXWq5ra2tXsEQERFVBOzB0J/sh50RERFVVXzYmf50WkVCREREVBbswSAiIiqGQyT6Y4JBRERUjOBOnnrjEAkREREpjj0YRERExXCIRH9MMIiIiIrhTp76Y4JBRERUjIY9GHrjHAwiIiJSHHswiIiIiuEqEv0xwSAiIiqGkzz1xyESIiIiUhx7MIiIiIrhKhL9sQeDiIioGKERih3lZd68eWjfvj0sLCxgY2NTts8lBGbMmIF69erB3Nwc/v7+uHTpkladjIwMDBgwAFZWVrCxscGwYcOQk5Ojc3xMMIiIiCqhgoICvP322/jwww/L/JpFixZh6dKlWLlyJY4dOwZLS0sEBAQgLy9PqjNgwACcO3cO0dHR+OWXX3Do0CGMHDlS5/g4REJERFSMkqtI8vPzkZ+fr1WmVquhVqv1anfWrFkAgA0bNpSpvhACS5YswbRp09CrVy8AQGRkJBwcHLBz5070798fCQkJiIqKwl9//QVvb28AwLJlyxAUFITPP/8c9evXL3uAgiqMvLw8ERYWJvLy8gwdClUAvB+oON4TlVNYWJgAoHWEhYUp1v769euFtbX1c+tdvnxZABCnT5/WKu/cubMYN26cEEKItWvXChsbG63rhYWFwtjYWPz44486xcUhkgokPz8fs2bNKpHpUvXE+4GK4z1ROYWGhuLevXtaR2ho6AuPIy0tDQDg4OCgVe7g4CBdS0tLg729vdb1GjVqwNbWVqpTVkwwiIiIypFarYaVlZXW8bThkalTp0KlUj3zuHDhwgv+BPJwDgYREVEFMXHiRAwZMuSZdVxdXWW17ejoCABIT09HvXr1pPL09HS0bNlSqnPr1i2t1z18+BAZGRnS68uKCQYREVEFUbduXdStW7dc2nZxcYGjoyNiYmKkhCI7OxvHjh2TVqL4+voiKysLJ0+eRJs2bQAA+/fvh0ajgY+Pj07vxyGSCkStViMsLEzvmcVUNfB+oOJ4T9CTUlJSEBcXh5SUFBQVFSEuLg5xcXFae1Y0a9YMO3bsAACoVCpMmDABc+fOxc8//4yzZ89i0KBBqF+/Pnr37g0AcHd3R2BgIEaMGIHjx4/j6NGjGDt2LPr376/bChIAKiEEN1wnIiKqZIYMGYKNGzeWKD9w4AC6du0K4FFSsX79emnYRQiBsLAwrFq1CllZWejYsSO+/vprvPzyy9LrMzIyMHbsWOzatQtGRkYIDg7G0qVLUbNmTZ3iY4JBREREiuMQCRERESmOCQYREREpjgkGERERKY4JRjV08OBBqFQqZGVlAXi0j31Zn8T3LCqVCjt37tS7HaKKiPc3kW6qVIIxZMgQaanNk4r/Qq2IduzYgXbt2sHa2hq1atXCK6+8ggkTJkjXZ86cKa1bVlq/fv1w8eLFcmm7IhsyZEipu+QFBgYaOrSnun//PkJDQ9G4cWOYmZmhbt266NKlC3766SdDh1bp3b59Gx9++CFeeuklqNVqODo6IiAgAEePHjV0aKW6cuUKVCoV4uLiSlzr2rWr1t8fRIbAjbYUUlhYCBMTE1mvjYmJQb9+/TBv3jz07NkTKpUK58+fR3R0tMJRls7c3Bzm5uYv5L0qmsDAQKxfv16rrCLvMTBq1CgcO3YMy5Ytg4eHB+7evYs//vgDd+/eLbf3LCgogKmpabm1X1EEBwejoKAAGzduhKurK9LT0xETE1Ou321lVl3uC9KDTo9Gq+AGDx4sevXqVaL8wIEDAoDIzMwUQgixfft24eHhIUxNTYWzs7P4/PPPteoDEDt27NAqs7a2FuvXrxdCCJGcnCwAiK1bt4rOnTsLtVot1q9fL65cuSLefPNNYWNjIywsLISHh4fYvXv3c+MeP3686Nq161Ovr1+/vsST+NavXy/F8eST8TIzMwUAceDAAals9+7dokmTJsLMzEx07dpVau/x91Hak/h27twpWrVqJdRqtXBxcREzZ84UhYWF0vWLFy+KTp06CbVaLdzd3cW+fftK/d4qsqfdL0I8umdMTEzEoUOHpLKFCxeKunXrirS0NCGEEL/++qvo0KGDsLa2Fra2tqJHjx4iKSlJqv/4/8+2bdtEx44dhZmZmfD29haJiYni+PHjok2bNsLS0lIEBgaKW7dulSlma2trsWHDhmfWycvLE5MnTxYNGzYUpqamonHjxmLNmjXS9YMHD4pXX31VmJqaCkdHRzFlyhSt/7ddunQRY8aMEePHjxd16tSR7s2zZ8+KwMBAYWlpKezt7cXAgQPF7du3yxR3Rff4z83BgwefWqf4/Z2SkiLefvttYW1tLWrXri169uwpkpOTtV6zevVq0axZM6FWq0XTpk1FRESEdO3x/bFlyxbh6+sr1Gq1eOWVV54Zw5NK+/P/WJcuXcT48eOl84yMDPH+++8LGxsbYW5uLgIDA8XFixel62FhYaJFixZabXz55ZfC2dlZOn/852Xu3LmiXr16olGjRkIIISIiIoSbm5tQq9XC3t5eBAcHlyl+qvqq1BBJWZw8eRLvvPMO+vfvj7Nnz2LmzJmYPn06NmzYoHNbU6dOxfjx45GQkICAgACMGTMG+fn5OHToEM6ePYuFCxeWaWMSR0dHnDt3Dn///Xep1/v164eJEyfilVdeQWpqKlJTU9GvX78yxXjt2jX07dsXb731FuLi4jB8+HBMnTr1ma85fPgwBg0ahPHjx+P8+fP473//iw0bNmDevHkAAI1Gg759+8LU1BTHjh3DypUrMWXKlDLFU1k87mJ+//33ce/ePZw+fRrTp0/HmjVrpCcR5ubmIiQkBCdOnEBMTAyMjIzQp08faDQarbbCwsIwbdo0nDp1CjVq1MB7772HyZMn46uvvsLhw4eRlJSEGTNmlCkuR0dH7NmzB//+++9T6wwaNAhbtmzB0qVLkZCQgP/+97/SfXjjxg0EBQXh1VdfxZkzZ7BixQqsXbsWc+fO1Wpj48aNMDU1xdGjR7Fy5UpkZWXh9ddfR6tWrXDixAlERUUhPT0d77zzji5fa4VVs2ZN1KxZEzt37izTk0oLCwsREBCAWrVq4fDhwzh69Chq1qyJwMBAFBQUAAA2bdqEGTNmYN68eUhISMD8+fMxffr0EhsjTZo0CRMnTsTp06fh6+uLt956S/FekyFDhuDEiRP4+eefERsbCyEEgoKCUFhYqFM7MTExSExMRHR0NH755RecOHEC48aNw+zZs5GYmIioqCh07txZ0dipEjN0hqOkwYMHC2NjY2Fpaal1mJmZSf9if++990S3bt20Xjdp0iTh4eEhnaOMPRhLlizRquPp6Slmzpypc9w5OTkiKChIABDOzs6iX79+Yu3atSIvL0+qU9q/MMrSgxEaGqr12YQQYsqUKc/swfDz8xPz58/Xes0333wj6tWrJ4QQYu/evaJGjRrixo0b0vVff/21UvZglHa/zJs3TwghRH5+vmjZsqV45513hIeHhxgxYsQz27t9+7YAIM6ePSuE+N//nyd7D7Zs2SIAiJiYGKksPDxcNG3atEwx//7776Jhw4bCxMREeHt7iwkTJogjR45I1xMTEwUAER0dXerrP/nkE9G0aVOh0WiksoiICFGzZk1RVFQkhHj0r99WrVppvW7OnDmie/fuWmXXrl0TAERiYmKZYq/otm/fLmrXri3MzMxE+/btRWhoqDhz5ox0/cn7+5tvvinxPebn5wtzc3Oxd+9eIYQQjRs3Fps3b9Z6jzlz5ghfX18hxP/ujwULFkjXCwsLRcOGDcXChQufG+/j15ubm5e4h42MjKQejIsXLwoA4ujRo9Jr79y5I8zNzcV3330nhCh7D4aDg4PIz8+Xyn744QdhZWUlsrOznxsvVT9Vrgfjtddek/Zjf3ysWbNGup6QkIAOHTpovaZDhw64dOkSioqKdHovb29vrfNx48Zh7ty56NChA8LCwhAfH1+mdiwtLbF7924kJSVh2rRpqFmzJiZOnIi2bdvi/v37OsVUXEJCQokH1Pj6+j7zNWfOnMHs2bOlf9XVrFkTI0aMQGpqKu7fv4+EhAQ4OTlp7Uv/vDYrqtLul1GjRgEATE1NsWnTJvzwww/Iy8vDl19+qfXaS5cu4d1334WrqyusrKzQqFEjAI+eD/AkLy8v6efHvR+enp5aZcWfXvg0nTt3xj///IOYmBj85z//wblz59CpUyfMmTMHABAXFwdjY2N06dKl1NcnJCTA19cXKpVKKuvQoQNycnJw/fp1qezxQ44eO3PmDA4cOKB1TzRr1gwAcPny5TLFXtEFBwfj5s2b+PnnnxEYGIiDBw+idevWpfZunjlzBklJSahVq5b0fdja2iIvLw+XL19Gbm4uLl++jGHDhml9Z3Pnzi3xfT35Z6dGjRrw9vZGQkJCmePetm1biXv4yb+bEhISUKNGDa2/B+rUqYOmTZvq9D7Ao/v2yXkX3bp1g7OzM1xdXfH+++9j06ZNev+dRVVHlZvkaWlpCTc3N62yJ//iLAuVSgVRbAf10roSLS0ttc6HDx+OgIAA7N69G/v27UN4eDi++OILfPTRR2V638aNG6Nx48YYPnw4Pv30U7z88svYtm0bhg4dWmp9I6NH+eGTsera5VmanJwczJo1C3379i1xzczMTO/2K5LS7pcn/fHHHwAe7c2fkZGh9f/8rbfegrOzM1avXo369etDo9GgefPmUhf5Y09O/n38i714WfFhlWcxMTFBp06d0KlTJ0yZMgVz587F7NmzMWXKFMUm6xa/t3NycvDWW29h4cKFJeo++djnys7MzAzdunVDt27dMH36dAwfPhxhYWElHp+dk5ODNm3aYNOmTSXaqFu3rvSwqdWrV5dI8I2NjRWN2cnJqcQ9rOt9YGRkJOvvvFq1auHUqVM4ePAg9u3bhxkzZmDmzJn466+/FFn6TpVblevBeB53d/cSy86OHj2Kl19+WfqDX7duXaSmpkrXL126VOas3MnJCaNGjcKPP/6IiRMnYvXq1bLibNSoESwsLJCbmwvg0b+mi/ewPH6k75OxFl+y5u7ujuPHj2uV/fnnn89879atWyMxMRFubm4lDiMjI7i7u+PatWta7/u8Niujy5cv4+OPP5Z+SQwePFhKBO7evYvExERMmzYNfn5+cHd3R2ZmpkHi9PDwwMOHD5GXlwdPT09oNBr8/vvvpdZ1d3eXxuAfO3r0KGrVqoWGDRs+9T1at26Nc+fOoVGjRiXuieK/dKoSDw8P6c/gk1q3bo1Lly7B3t6+xPdhbW0NBwcH1K9fH//880+J6y4uLlptPfln5+HDhzh58iTc3d0V+wzu7u54+PAhjh07JpU9vn89PDwAPPq7JC0tTeu+KG35a2lq1KgBf39/LFq0CPHx8bhy5Qr279+vWPxUeVW7BGPixImIiYnBnDlzcPHiRWzcuBHLly/H//3f/0l1Xn/9dSxfvhynT5/GiRMnMGrUqDItQZ0wYQL27t2L5ORknDp1CgcOHCjTXxQzZ87E5MmTcfDgQSQnJ+P06dP44IMPUFhYiG7dugF4lHAkJycjLi4Od+7cQX5+PszNzdGuXTssWLAACQkJ+P333zFt2jSttkeNGoVLly5h0qRJSExMxObNm587oXXGjBmIjIzErFmzcO7cOSQkJGDr1q1S2/7+/nj55ZcxePBgnDlzBocPH8ann3763M9ZEeXn5yMtLU3ruHPnDoqKijBw4EAEBARg6NChWL9+PeLj4/HFF18AAGrXro06depg1apVSEpKwv79+xESElLu8Xbt2hX//e9/cfLkSVy5cgV79uzBJ598gtdee00aphk8eDA++OAD7Ny5E8nJyTh48CC+++47AMDo0aNx7do1fPTRR7hw4QJ++uknhIWFISQkROoRK82YMWOQkZGBd999F3/99RcuX76MvXv3YujQoToPLVZEd+/exeuvv45vv/0W8fHxSE5Oxvfff49FixahV69eJeoPGDAAdnZ26NWrFw4fPix9z+PGjZN6TGfNmoXw8HAsXboUFy9exNmzZ7F+/XosXrxYq62IiAjs2LEDFy5cwJgxY5CZmYkPPvhAsc/WpEkT9OrVCyNGjMCRI0dw5swZDBw4EA0aNJA+W9euXXH79m0sWrQIly9fRkREBH799dfntv3LL79g6dKliIuLw9WrVxEZGQmNRoOmTZsqFj9VYgadAaIwXZepmpiYiJdeekl89tlnWvVv3LghunfvLiwtLUWTJk3Enj17Sp3kWXx52NixY0Xjxo2FWq0WdevWFe+//764c+fOc+Pev3+/CA4OFk5OTsLU1FQ4ODiIwMBAcfjwYalOXl6eCA4OFjY2NtIyVSGEOH/+vPD19RXm5uaiZcuW0nLRJ5ep7tq1S1pG1qlTJ7Fu3brnLlONiooS7du3F+bm5sLKykq0bdtWrFq1SrqemJgoOnbsKExNTcXLL78soqKiKuUkTxRb/gtANG3aVMyaNUvUq1dP6//fDz/8IExNTUVcXJwQQojo6Gjh7u4u1Gq18PLyEgcPHtT6Dkq7T4rfi0KU/v0/zfz584Wvr6+wtbUVZmZmwtXVVYwbN04rzgcPHoiPP/5Y1KtXT5iamgo3Nzexbt066XpZlqk+ucTxsYsXL4o+ffpISx2bNWsmJkyYoDXRsbLKy8sTU6dOFa1btxbW1tbCwsJCNG3aVEybNk3cv39fCFFy8ndqaqoYNGiQsLOzE2q1Wri6uooRI0aIe/fuSXU2bdokWrZsKUxNTUXt2rVF586dxY8//iiE+N/9sXnzZtG2bVthamoqPDw8xP79+8sUs5xlqtbW1sLc3FwEBARoLVMVQogVK1YIJycnYWlpKQYNGiTmzZtX6jLVJx0+fFh06dJF1K5dW5ibmwsvLy+xbdu2MsVPVR8f105EZABXrlyBi4sLTp8+XW679BIZUrUbIiEiIqLyxwTjBRg1apTWUrUnj8dLIokAPPU+qVmzJg4fPmzo8OgF4t8bVNlxiOQFuHXrFrKzs0u9ZmVlBXt7+xccEVVUSUlJT73WoEGDavvMmOqIf29QZccEg4iIiBTHIRIiIiJSHBMMIiIiUhwTDCIiIlIcEwwiIiJSHBMMIiIiUhwTDCIiIlIcEwwiIiJS3P8DILvJow9xs/4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Scatter Plot for Visual Check"
      ],
      "metadata": {
        "id": "fX8S78pgfr_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df['Hours_Studied'], df['Exam_Score'])\n",
        "plt.xlabel('Hours Studied')\n",
        "plt.ylabel('Exam Score')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "mJ5P0Ue1fwuf",
        "outputId": "d507e9ec-bb7e-4750-c9f2-9eda284c880a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15  What is causation? Explain difference between correlation and causation with an example?\n",
        "\n",
        "    ->Causation means that one event or variable directly affects another. In other words, changes in one variable cause changes in the other.\n",
        "\n",
        "  Example: If you increase the temperature of water, it causes the water to boil faster.\n",
        "  Here, the relationship is not just an association â€” itâ€™s a cause-and-effect link.\n",
        "\n",
        "   * Difference Between Correlation and Causation\n",
        "      Aspect\t       Correlation\t          Causation\n",
        "  Definition   \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YyLBkf5uf4fm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16  What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "    ->An optimizer in machine learning is an algorithm that adjusts the parameters (like weights and biases) of a model to minimize the loss function.\n",
        "\n",
        "  Think of it as the \"coach\" guiding the model to improve its performance step by step.\n",
        "  Without optimizers, the model wouldnâ€™t know how to update itself to get better predictions.\n",
        "\n",
        "    *Different Types of Optimizers\n",
        "   * Gradient Descent (GD)\n",
        "     Idea: Updates parameters in the opposite direction of the gradient of the loss function.\n",
        "   Update Rule:\n",
        "                 0 = 0 a.vl(0)\n",
        "    where a = learning rate.\n",
        "\n",
        "  * Stochastic Gradient Descent (SGD)\n",
        "  Idea: Instead of using the whole dataset, updates parameters using one sample (or mini-batch) at a time.\n",
        "  Faster and works well with large datasets.\n",
        "  More noisy updates, but helps escape local minima.\n",
        "  Example: Training deep neural networks often uses SGD.\n",
        "\n",
        "   * Mini-Batch Gradient Descent\n",
        "   Idea: A compromise between GD and SGD â€” uses small batches of data for updates.\n",
        "   Efficient and stable.\n",
        "   Example: Commonly used in deep learning frameworks like TensorFlow and PyTorch.\n",
        "\n",
        "    * momentum\n",
        "   Idea: Adds a fraction of the previous update to the current update, like rolling a ball downhill.\n",
        "   Helps accelerate learning and smooths oscillations.\n",
        "   Example: Training CNNs often uses SGD with momentum.\n",
        "\n",
        "\n",
        "    * Adam (Adaptive Moment Estimation)\n",
        "     Idea: Combines Momentum and RMSProp.\n",
        "     Most popular optimizer in deep learning.\n",
        "     Fast convergence, efficient, widely used.\n",
        "     Example: Training transformers (like BERT, GPT) uses Adam.\n",
        "     * Quick Python Example (Adam Optimizer in Keras)\n"
      ],
      "metadata": {
        "id": "2D9synuphZRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Simple neural network\n",
        "model = Sequential([\n",
        "    Dense(10, activation='relu', input_shape=(5,)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile with Adam optimizer\n",
        "model.compile(optimizer=Adam(learning_rate=0.01),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izZjuYFhk9bZ",
        "outputId": "e571fa95-979d-4e01-8f3a-beb5df217afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "17 What is sklearn.linear_model ?\n",
        "\n",
        "    ->sklearn.linear_model is a module in scikit-learn (sklearn) that provides implementations of linear models for regression and classification tasks. Linear models are algorithms that assume a linear relationship between input features (X) and the target variable (y).\n",
        "\n",
        "     * Here are the most commonly used ones:\n",
        "\n",
        "   * Linear Regression\n",
        "   Fits a straight line to predict continuous values.\n",
        "   Example: predicting house prices based on size.\n",
        "\n",
        "    * Logistic Regression\n",
        "  Used for classification problems (binary or multiclass).\n",
        "  Example: predicting whether an email is spam or not.\n",
        "\n",
        "  * Ridge Regression\n",
        "  Linear regression with L2 regularization (penalizes large coefficients).\n",
        "  Helps reduce overfitting.\n",
        "\n",
        "  * Lasso Regression\n",
        " Linear regression with L1 regularization (can shrink some coefficients to zero).\n",
        " Useful for feature selection.\n",
        "\n",
        "  * ElasticNet\n",
        "  Combines L1 and L2 regularization.\n",
        "  Balances between Ridge and Lasso.\n",
        "\n",
        "  * Perceptron\n",
        "   A simple linear classifier for binary classification.\n",
        "\n",
        "  * SGDClassifier / SGDRegressor\n",
        "  Linear models trained using Stochastic Gradient Descent.\n",
        "  Efficient for large datasets.\n"
      ],
      "metadata": {
        "id": "fkUCYTO6-ajK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Sample data\n",
        "X = [[1], [2], [3], [4], [5]]\n",
        "y = [2, 4, 6, 8, 10]\n",
        "\n",
        "# Create and train model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict\n",
        "print(model.predict([[6]]))  # Output: [12.]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXlGZfupAUjX",
        "outputId": "dbb5eac9-cefe-4f22-803f-5fe9691e9182"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "18  What does model.fit() do? What arguments must be given?\n",
        "\n",
        "    -> fit() is the training method in scikit-learn.\n",
        "    It takes your training data (features and labels) and learns the relationship between them.\n",
        "\n",
        "   * Internally, it:\n",
        "   Estimates parameters (like coefficients in linear regression).\n",
        "   Optimizes them using algorithms (like gradient descent or closed-form solutions).\n",
        "   Stores the learned parameters inside the model object for later use (e.g., with predict()).\n",
        "    * Arguments\n",
        "   The exact arguments depend on the type of model (regression, classification, clustering), but the common ones are:\n",
        "\n",
        "    * X (features)\n",
        "   Shape: (n_samples, n_features)\n",
        "   Example: a matrix of input variables (like house size, number of rooms)\n",
        "\n",
        "   * y (target labels)\n",
        "   Shape: (n_samples,) or (n_samples, n_outputs)\n",
        "   Example: house prices (for regression) or class labels (for classification).\n",
        "\n",
        "  * Optional arguments (depending on model):\n",
        "   sample_weight: array of weights for each sample (useful if some samples are more important).\n",
        "   epochs, batch_size, etc. (for iterative models like SGDClassifier).\n",
        "   classes: required for some classifiers (e.g., partial_fit in SGDClassifier).\n",
        "\n"
      ],
      "metadata": {
        "id": "cKqQ5os4Afup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Features (X) and labels (y)\n",
        "X = [[0, 0], [1, 1], [2, 2]]\n",
        "y = [0, 1, 1]\n",
        "\n",
        "# Create model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train model\n",
        "model.fit(X, y)\n",
        "\n",
        "# After fitting, you can predict\n",
        "print(model.predict([[3, 3]]))  # Output: [1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1UUsIDwCF-G",
        "outputId": "e04bf271-e4dc-4fd9-ddcd-99a45a521061"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "19 What does model.predict() do? What arguments must be given?\n",
        "\n",
        "    ->predict() is the inference step in scikit-learn models.\n",
        "    After you train a model with fit(), the model has learned parameters (like coefficients or weights).\n",
        "    predict() applies those learned parameters to new input data (X) and produces predictions:\n",
        "\n",
        "   Regression models â†’ continuous values (e.g., predicted house price).\n",
        "   Classification models â†’ class labels (e.g., spam or not spam).\n",
        "   Think of it as:\n",
        "\n",
        "      * Arguments for model.predict()\n",
        "     Required:\n",
        "      X (features)\n",
        "      Shape: (n_samples, n_features)\n",
        "     Example: a matrix of input variables for which you want predictions.\n",
        "\n",
        "    * Optional (depending on model type):\n",
        "     Most models only require X.\n",
        "     Related methods exist for extra detail:\n",
        "     predict_proba(X) â†’ returns class probabilities (for classifiers like Logistic Regression).\n",
        "     decision_function(X) â†’ returns raw decision scores.\n"
      ],
      "metadata": {
        "id": "8cyLIQU_CLKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Training data\n",
        "X = [[1], [2], [3], [4], [5]]\n",
        "y = [2, 4, 6, 8, 10]\n",
        "\n",
        "# Train model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict new value\n",
        "print(model.predict([[6]]))  # Output: [12.]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIwlz0saFBTi",
        "outputId": "8d2f6243-7471-46fb-a128-bbd36268d4f9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 20 What are continuous and categorical variables?\n",
        "\n",
        "    ->Continuous variables are numerical values that can take on an infinite range within an interval, while categorical variables represent distinct groups or categories.\n",
        "\n",
        "     * Continuous Variables\n",
        "  Definition: Quantitative variables that can take on any value within a range.\n",
        "  Characteristics:\n",
        "     Measured, not counted.\n",
        "     Can include fractions and decimals.\n",
        "     Infinite possible values within a given interval.\n",
        "\n",
        "     * Examples:\n",
        "   Height (e.g., 170.5 cm)\n",
        "   Weight (e.g., 65.2 kg)\n",
        "   Temperature (e.g., 36.7 Â°C)\n",
        "   Time (e.g., 2.35 seconds)\n",
        "\n",
        "  Use in ML/Stats: Suitable for regression models, correlation analysis, and continuous probability distributions.\n",
        "\n",
        "   * Categorical Variables\n",
        "   Definition: Qualitative variables that describe characteristics or group membership.\n",
        "   Characteristics:\n",
        "     Values are labels or categories, not numbers with mathematical meaning.\n",
        "     Can be nominal (unordered categories) or ordinal (ordered categories).\n",
        "\n",
        "   * Examples:\n",
        "     Gender (Male, Female, Other)\n",
        "     Blood type (A, B, AB, O)\n",
        "     Color (Red, Blue, Green)\n",
        "     Education level (High School, Bachelorâ€™s, Masterâ€™s, PhD â†’ ordinal)\n",
        "\n",
        "   Use in ML/Stats: Often require encoding (e.g., one-hot encoding, label encoding) before being used in machine learning models\n",
        "\n",
        "aspect\t     Continuous Variables\t    Categorical Variables\n",
        "Type of data,\t Quantitative (numeric)\t, Qualitative (labels/groups),\n",
        "\n",
        "Possible values,\t Infinite within a range,\t   Finite predefined categories,\n",
        "\n",
        "Examples\t     Height, weight, time\tGender,    color, blood type,\n",
        "ML usage\t   Regression, correlation,\t    Classification, encoding requird,\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pNPaUenzFIgo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21  What is feature scaling? How does it help in Machine Learning?\n",
        "    ->Feature scaling is the process of transforming numerical features so they share a common scale, typically by normalization or standardization. It helps machine learning models perform better by ensuring no single feature dominates due to its magnitude.\n",
        "\n",
        "    * What is Feature Scaling?\n",
        "  Definition: A preprocessing step where numerical features are adjusted to a specific range or distribution.\n",
        "  Techniques:\n",
        "  Normalization: Rescales values to a fixed range, usually [0, 1].\n",
        "                x2=    \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "              \n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ytaWMulQIPQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21  What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "    ->Feature scaling is the process of transforming numerical features so they share a common scale, typically by normalization or standardization. It helps machine learning models perform better by ensuring no single feature dominates due to its magnitude.\n",
        "\n",
        "    * What is Feature Scaling?\n",
        "  Definition: A preprocessing step where numerical features are adjusted to a specific range or distribution.\n",
        "  Techniques:\n",
        "  Normalization: Rescales values to a fixed range, usually [0, 1].\n",
        "              \n",
        "    * Why Feature Scaling Helps in ML\n",
        "   Equal Contribution: Prevents large-scale features (e.g., income in dollars vs. age in years) from dominating smaller-scale ones.\n",
        "   Improves Convergence: Algorithms like gradient descent converge faster when features are scaled.\n",
        "   Distance-Based Models: Essential for algorithms like KNN, SVM, and clustering, which rely on distance metrics.\n",
        "   Regularization: Ensures penalties (L1/L2) apply fairly across coefficients.\n",
        "   Better Accuracy: Leads to more stable and accurate predictions.\n"
      ],
      "metadata": {
        "id": "VnHV_TvKJUYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "X = np.array([[10], [200], [3000]])\n",
        "\n",
        "# Standardization\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit_transform(X))\n",
        "# Output: values with mean 0, std 1\n",
        "\n",
        "# Normalization\n",
        "scaler = MinMaxScaler()\n",
        "print(scaler.fit_transform(X))\n",
        "# Output: values scaled between 0 and 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VzoKga3KOD1",
        "outputId": "8a2335c0-a033-4329-d615-2c7f5f992b08"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.77546676]\n",
            " [-0.636468  ]\n",
            " [ 1.41193477]]\n",
            "[[0.        ]\n",
            " [0.06354515]\n",
            " [1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "22 How do we perform scaling in Python?\n",
        "\n",
        "    -> Methods of Scaling in Python\n",
        "  *  Standardization (Z-score scaling)\n",
        "     Transforms data to have mean = 0 and standard deviation = 1.\n",
        "     Useful when features follow a normal distribution.\n",
        "\n"
      ],
      "metadata": {
        "id": "T-XIhGoOKXQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "X = np.array([[10], [200], [3000]])\n",
        "\n",
        "# Standardization\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(X_scaled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Za9mKQ-LEiD",
        "outputId": "f345ed29-071e-46ea-e67c-366b9ca2d660"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.77546676]\n",
            " [-0.636468  ]\n",
            " [ 1.41193477]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "   * Normalization (Min-Max scaling)\n",
        "     Rescales values to a fixed range, usually [0, 1].\n",
        "     Useful when you want bounded values."
      ],
      "metadata": {
        "id": "F9pJJ44uLiFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Normalization\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(X_scaled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlDR03BuLucC",
        "outputId": "8c7ea728-ef43-4690-97ac-0281993798fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.        ]\n",
            " [0.06354515]\n",
            " [1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "   * Robust Scaling\n",
        "   Uses median and interquartile range (IQR) instead of mean and standard deviation.\n",
        "   Useful when data contains outliers."
      ],
      "metadata": {
        "id": "bnhnF-9eLxgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "scaler = RobustScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(X_scaled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOO8es_JL-q1",
        "outputId": "da1c8d08-09ce-452c-dfc3-95151e66a677"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.1270903]\n",
            " [ 0.       ]\n",
            " [ 1.8729097]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "   * MaxAbs Scaling\n",
        "  Scales data by dividing by the maximum absolute value.\n",
        "  Keeps data in range [-1, 1].\n",
        "  Useful for sparse data."
      ],
      "metadata": {
        "id": "JsjohE4kMDuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "\n",
        "scaler = MaxAbsScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(X_scaled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQLMobfbMPfs",
        "outputId": "fc7fe418-a2b8-4766-eac8-084d99c98001"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00333333]\n",
            " [0.06666667]\n",
            " [1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  23  What is sklearn.preprocessing?\n",
        "  \n",
        "    ->sklearn.preprocessing is a module in scikit-learn that provides tools to transform raw data into formats suitable for machine learning models. It includes functions for scaling, normalizing, encoding, and imputing data so that algorithms can learn effectively.\n",
        "\n",
        "   * What sklearn.preprocessing Does\n",
        "   Transforms raw feature vectors into representations better suited for downstream estimators.\n",
        "   Helps ensure that features are on comparable scales, categorical data is encoded numerically, and missing values are handled.\n",
        "   Many ML algorithms (like linear models, SVMs, KNN) perform poorly without preprocessing because they are sensitive to feature magnitude and representation.\n",
        "\n",
        "  * Scaling & Normalization\n",
        "  StandardScaler â†’ mean = 0, variance = 1.\n",
        "  MinMaxScaler â†’ scales values to [0, 1].\n",
        "  RobustScaler â†’ uses median and IQR, robust to outliers.\n",
        "  Normalizer â†’ scales samples individually to unit norm.\n",
        "\n",
        "  *  Encoding Categorical Data\n",
        "  LabelEncoder â†’ converts labels into integers.\n",
        "  OneHotEncoder â†’ creates binary columns for categories.\n",
        "  OrdinalEncoder â†’ encodes categories with integer values (ordered).\n",
        "\n",
        "   * Imputation (Handling Missing Values)\n",
        "   SimpleImputer â†’ replaces missing values with mean, median, or constant.\n",
        "  KNNImputer â†’ fills missing values using nearest neighbors.\n",
        "\n",
        "   * polynomial & Interaction Features\n",
        "   PolynomialFeatures â†’ generates polynomial combinations of features.\n",
        "   Useful for capturing non-linear relationships.\n",
        "\n",
        "  *  Discretization\n",
        "  KBinsDiscretizer â†’ converts continuous features into discrete bins.\n"
      ],
      "metadata": {
        "id": "pjvNucf_MVS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Continuous data scaling\n",
        "X = np.array([[1.0], [2.0], [3.0]])\n",
        "scaler = StandardScaler()\n",
        "print(scaler.fit_transform(X))  # mean=0, std=1\n",
        "\n",
        "# Categorical encoding\n",
        "encoder = OneHotEncoder()\n",
        "y = np.array([['red'], ['green'], ['blue']])\n",
        "print(encoder.fit_transform(y).toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0k-pMVrNvU4",
        "outputId": "69c85f7a-543f-4f94-c5ea-06fd6db97e88"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.22474487]\n",
            " [ 0.        ]\n",
            " [ 1.22474487]]\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "24 How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "    ->Why Split Data?\n",
        "    To evaluate how well a model generalizes to unseen data.\n",
        "    Training set â†’ used to fit the model (learn parameters).\n",
        "    Test set â†’ used to evaluate the modelâ€™s performance.\n",
        "    Sometimes a validation set is also used for tuning hyperparameters.\n",
        "\n",
        "  * How to Split Data in Python (scikit-learn)\n",
        "  The most common way is using train_test_split from sklearn.model_selection."
      ],
      "metadata": {
        "id": "mTHkYyjGNz1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Sample dataset\n",
        "X = np.array([[1], [2], [3], [4], [5], [6], [7], [8]])  # Features\n",
        "y = np.array([1, 2, 3, 4, 5, 6, 7, 8])                  # Labels\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training set:\", X_train, y_train)\n",
        "print(\"Testing set:\", X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt6ZaWPjOWxU",
        "outputId": "5327071c-1582-4670-abda-cf67133f74cb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: [[1]\n",
            " [8]\n",
            " [3]\n",
            " [5]\n",
            " [4]\n",
            " [7]] [1 8 3 5 4 7]\n",
            "Testing set: [[2]\n",
            " [6]] [2 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  * Key Parameters in train_test_split\n",
        "   test_size â†’ fraction or number of samples for testing (e.g., 0.2 = 20%).\n",
        "   train_size â†’ fraction or number of samples for training (optional if test_size is given).\n",
        "   random_state â†’ ensures reproducibility (same split every run).\n",
        "  shuffle â†’ whether to shuffle before splitting (default = True).\n",
        "  stratify â†’ ensures class proportions are preserved (important for classification)."
      ],
      "metadata": {
        "id": "hX5Pjl9BOjSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25 Explain data encoding?\n",
        "\n",
        "    ->Definition: Data encoding is the process of converting categorical (non-numeric) variables into numerical formats so that machine learning algorithms can process them.\n",
        "    ML models generally work with numbers, not text labels, so encoding is essential when dealing with categorical data like gender, color, country, product type.\n",
        "\n",
        "\n",
        "   *  Label Encoding\n",
        "   Converts categories into integers.\n",
        "   Example:\n",
        "        [\"Red\", \"Green\", \"Blue\"] â†’ [0, 1, 2]\n",
        "   Useful for ordinal data (where order matters, e.g., education level).\n",
        "   Limitation: Implies an order even for nominal categories (e.g., \"Red\" < \"Blue\"), which may mislead models.\n"
      ],
      "metadata": {
        "id": "kxIbTk1YOxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "colors = [\"Red\", \"Green\", \"Blue\", \"Green\"]\n",
        "encoder = LabelEncoder()\n",
        "encoded = encoder.fit_transform(colors)\n",
        "print(encoded)  # [2, 1, 0, 1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6ogn8-DPdQ5",
        "outputId": "d31b57a9-87f8-41ef-8857-023fd5ce9270"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "   * One-Hot Encoding\n",
        "   Creates binary columns for each category.\n",
        "   Example:\n",
        "      [\"Red\", \"Green\", \"Blue\"] â†’ [[1,0,0], [0,1,0], [0,0,1]]\n",
        "   Useful for nominal data (no inherent order).\n",
        "   Increases dimensionality if many categories exist.   \n"
      ],
      "metadata": {
        "id": "LMexkg6KPgyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "colors = np.array([[\"Red\"], [\"Green\"], [\"Blue\"], [\"Green\"]])\n",
        "encoder = OneHotEncoder()\n",
        "encoded = encoder.fit_transform(colors).toarray()\n",
        "print(encoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjTa0e3nPvr1",
        "outputId": "2f59a84e-0450-49ca-a862-b7d5014382fc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "   * Ordinal Encoding\n",
        "   Assigns integers to categories based on a defined order.\n",
        "   Example:\n",
        "     Education levels: [\"High School\", \"Bachelor\", \"Master\", \"PhD\"] â†’ [0, 1, 2, 3]\n",
        "   Useful when categories have a natural ranking.\n",
        "\n",
        "  *  Binary Encoding / Hash Encoding\n",
        "   Converts categories into binary digits or hashed values.\n",
        "   Useful when the number of categories is very large (e.g., thousands of unique product IDs)."
      ],
      "metadata": {
        "id": "VXQXsZURP1Ic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uW-UbcFBKNzY"
      }
    }
  ]
}